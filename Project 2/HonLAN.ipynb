{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, r_regression, f_regression\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF, CompoundKernel, Product, Sum, ExpSineSquared, RationalQuadratic\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# boost algorithm\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import lightgbm as lgb\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, Linear, Dropout\n",
    "from torch.nn.functional import tanh, softmax, mse_loss, relu, sigmoid\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# bio library\n",
    "import biosppy\n",
    "from biosppy import storage\n",
    "from biosppy.signals import ecg\n",
    "\n",
    "DATA_DIR = \"Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train_df = pd.read_csv(os.path.join(DATA_DIR, \"X_train.csv\"), header=0, index_col=0)\n",
    "X_test_df = pd.read_csv(os.path.join(DATA_DIR, \"X_test.csv\"), header=0, index_col=0)\n",
    "y_train_df = pd.read_csv(os.path.join(DATA_DIR, \"y_train.csv\"), header=0, index_col=0)\n",
    "\n",
    "X_train = X_train_df.values\n",
    "X_test = X_test_df.values\n",
    "y_train = y_train_df.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 获取有效长度\n",
    "X_train_len = []\n",
    "for row in X_train:\n",
    "    tail_id = np.where(np.isnan(row))[0]\n",
    "    if tail_id.shape[0] > 0:\n",
    "        X_train_len.append(tail_id[0])\n",
    "    else:\n",
    "        X_train_len.append(X_train.shape[1])\n",
    "\n",
    "X_test_len = []\n",
    "for row in X_test:\n",
    "    tail_id = np.where(np.isnan(row))[0]\n",
    "    if tail_id.shape[0] > 0:\n",
    "        X_test_len.append(tail_id[0])\n",
    "    else:\n",
    "        X_test_len.append(X_test.shape[1])\n",
    "\n",
    "X_train_len, X_test_len = np.array(X_train_len), np.array(X_test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ecg features\n",
    "ts_lst = []\n",
    "filtered_lst = []\n",
    "rpeaks_lst = []\n",
    "templates_ts_lst = []\n",
    "templates_lst = []\n",
    "heart_rate_ts_lst = []\n",
    "heart_rate_lst = []\n",
    "for signal, sig_len in zip(X_train, X_train_len):\n",
    "    ts, filtered, rpeaks, templates_ts, templates, heart_rate_ts, heart_rate = ecg.ecg(signal[:sig_len], sampling_rate=300., show=False)\n",
    "    ts_lst.append(ts) # Signal time axis reference (seconds)\n",
    "    filtered_lst.append(filtered) # Filtered ECG signal\n",
    "    rpeaks_lst.append(rpeaks) # R-peak location indices\n",
    "    templates_ts_lst.append(templates_ts) # Templates time axis reference\n",
    "    templates_lst.append(templates) # Extracted heartbeat templates\n",
    "    heart_rate_ts_lst.append(heart_rate_ts) # Heart rate time axis reference (seconds)\n",
    "    heart_rate_lst.append(heart_rate) # Instantaneous heart rate (bpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average template\n",
    "max_height = None\n",
    "for templates in templates_lst:\n",
    "    for template in templates:\n",
    "        if max_height is None or np.max(template) > max_height:\n",
    "            max_height = np.max(template)\n",
    "\n",
    "# scaler现在只是简单的缩放，不确定绝对高度有没有用\n",
    "def scaler(template: np.array):\n",
    "    result = template / max_height\n",
    "    return result\n",
    "\n",
    "def get_average_templates(templates):\n",
    "    templates = scaler(templates)\n",
    "    avg_templates = templates.sum(axis=0) / templates.shape[0]\n",
    "    return avg_templates\n",
    "\n",
    "avg_templates_lst = [get_average_templates(templates) for templates in templates_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_templates_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Hongyi LAN\\Desktop\\AML_Project\\Project 2\\HonLAN.ipynb 单元格 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hongyi%20LAN/Desktop/AML_Project/Project%202/HonLAN.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 测试获取RQPST\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Hongyi%20LAN/Desktop/AML_Project/Project%202/HonLAN.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m templates \u001b[39m=\u001b[39m avg_templates_lst[\u001b[39m10\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hongyi%20LAN/Desktop/AML_Project/Project%202/HonLAN.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_PQRST\u001b[39m(template: np\u001b[39m.\u001b[39marray):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hongyi%20LAN/Desktop/AML_Project/Project%202/HonLAN.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# get R\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hongyi%20LAN/Desktop/AML_Project/Project%202/HonLAN.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     R_id \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(templates \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mmax(templates))[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'avg_templates_lst' is not defined"
     ]
    }
   ],
   "source": [
    "# 测试获取RQPST\n",
    "templates = avg_templates_lst[10]\n",
    "\n",
    "def get_PQRST(template: np.array):\n",
    "    # get R\n",
    "    R_id = np.where(templates == np.max(templates))[0][0]\n",
    "    R = templates[R_id]\n",
    "\n",
    "    # get Q\n",
    "    Q_id = np.where(templates[:R_id] == np.min(templates[:R_id]))[0][0]\n",
    "    Q = templates[Q_id]\n",
    "\n",
    "    # get P\n",
    "    P_id = np.where(templates[:Q_id] == np.max(templates[:Q_id]))[0][0]\n",
    "    P = templates[P_id]\n",
    "\n",
    "    # get S\n",
    "    S_id = np.where(templates[R_id + 1:] == np.min(templates[R_id + 1:]))[0][0] + R_id + 1\n",
    "    S = templates[S_id]\n",
    "\n",
    "    # get T\n",
    "    T_id = np.where(templates[S_id + 1:] == np.max(templates[S_id + 1:]))[0][0] + S_id + 1\n",
    "    T = templates[T_id]\n",
    "\n",
    "    assert (P_id < Q_id and Q_id < R_id and R_id < S_id and S_id < T_id)\n",
    "\n",
    "    # cal interval\n",
    "    QRS = S_id - Q_id\n",
    "    PR = R_id - P_id\n",
    "    PQ = R_id - Q_id\n",
    "    ST = T_id - S_id\n",
    "    QT = T_id - Q_id\n",
    "    return (R, Q, P, S, T), (R_id, Q_id, P_id, S_id, T_id), (QRS, PR, PQ, ST, QT)\n",
    "\n",
    "(R, Q, P, S, T), (R_id, Q_id, P_id, S_id, T_id), (QRS, PR, PQ, ST, QT) = get_PQRST(templates)\n",
    "\n",
    "plt.plot(np.arange(0, templates.shape[0], 1), templates)\n",
    "plt.scatter([R_id, Q_id, P_id, S_id, T_id], [R, Q, P, S, T], c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get P Q R S T\n",
    "for templates in avg_templates_lst:\n",
    "    R_id = np.where(templates == np.max(templates))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
