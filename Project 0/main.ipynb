{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, Linear, Dropout\n",
    "from torch.nn.functional import tanh, softmax, mse_loss, relu\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split data\n",
    "data_train = pd.read_csv('Data/train.csv', header=0, index_col=0)\n",
    "data_test = pd.read_csv('Data/test.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "x_train, y_train = data_train.iloc[:, 1:].to_numpy(), data_train.iloc[:, 0].to_numpy().reshape((-1, 1))\n",
    "x_test = data_test.to_numpy()\n",
    "\n",
    "# scaler_x, scaler_y = StandardScaler(), StandardScaler()\n",
    "# x_train = scaler_x.fit_transform(x_train)\n",
    "# y_train = scaler_y.fit_transform(y_train)\n",
    "# x_test = scaler_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>-66.002423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>451.406504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>-461.676417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>40.501209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>-126.744722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id           y\n",
       "0  10000  -66.002423\n",
       "1  10001  451.406504\n",
       "2  10002 -461.676417\n",
       "3  10003   40.501209\n",
       "4  10004 -126.744722"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "class LR_Predictor(object):\n",
    "    def __init__(self) -> None:\n",
    "        self.regressor = LinearRegression()\n",
    "    \n",
    "    def train(self, x_train, y_train) -> None:\n",
    "        self.regressor.fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, x_test) -> None:\n",
    "        y_test = self.regressor.predict(x_test)\n",
    "        return y_test\n",
    "\n",
    "rp = LR_Predictor()\n",
    "rp.train(x_train, y_train)\n",
    "# y_test = scaler_y.inverse_transform(rp.predict(x_test).reshape((-1, 1)))\n",
    "y_test = rp.predict(x_test).reshape((-1, 1))\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test, columns=[\"y\"])\n",
    "y_test_df[\"Id\"] = data_test.index.tolist()\n",
    "y_test_df = y_test_df[[\"Id\", \"y\"]]\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.to_csv(\"./Result/result_1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "x_train, y_train = data_train.iloc[:, 1:].to_numpy(), data_train.iloc[:, 0].to_numpy().reshape((-1, 1))\n",
    "x_test = data_test.to_numpy()\n",
    "\n",
    "# scaler_x, scaler_y = StandardScaler(), StandardScaler()\n",
    "# x_train = scaler_x.fit_transform(x_train)\n",
    "# y_train = scaler_y.fit_transform(y_train)\n",
    "# x_test = scaler_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "class Ridge_Predictor(object):\n",
    "    def __init__(self) -> None:\n",
    "        self.regressor = KernelRidge(alpha=1.0, kernel=\"linear\")\n",
    "    \n",
    "    def train(self, x_train, y_train) -> None:\n",
    "        self.regressor.fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, x_test) -> None:\n",
    "        y_test = self.regressor.predict(x_test)\n",
    "        return y_test\n",
    "\n",
    "rp = Ridge_Predictor()\n",
    "rp.train(x_train, y_train)\n",
    "# y_test = scaler_y.inverse_transform(rp.predict(x_test).reshape((-1, 1)))\n",
    "y_test = rp.predict(x_test).reshape((-1, 1))\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test, columns=[\"y\"])\n",
    "y_test_df[\"Id\"] = data_test.index.tolist()\n",
    "y_test_df = y_test_df[[\"Id\", \"y\"]]\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.to_csv(\"./Result/result_1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "x_train, y_train = data_train.iloc[:, 1:].to_numpy(), data_train.iloc[:, 0].to_numpy().reshape((-1, 1))\n",
    "x_test = data_test.to_numpy()\n",
    "\n",
    "scaler_x, scaler_y = StandardScaler(), StandardScaler()\n",
    "x_train = scaler_x.fit_transform(x_train)\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "x_test = scaler_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>-66.138443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>452.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>-461.396098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>39.640058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>-126.675123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id           y\n",
       "0  10000  -66.138443\n",
       "1  10001  452.242400\n",
       "2  10002 -461.396098\n",
       "3  10003   39.640058\n",
       "4  10004 -126.675123"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "class GPR_Predictor(object):\n",
    "    def __init__(self, n_clusters=20) -> None:\n",
    "        self.n_clusters = n_clusters\n",
    "        self.km = KMeans(n_clusters=self.n_clusters, random_state=0, n_init=\"auto\")\n",
    "        self.regressors = []\n",
    "    \n",
    "    def train(self, x_train, y_train) -> None:\n",
    "        self.km.fit(x_train)\n",
    "        for cluster_i in range(self.n_clusters):\n",
    "            x_cluster = x_train[self.km.labels_ == cluster_i]\n",
    "            y_cluster = y_train[self.km.labels_ == cluster_i].reshape((-1, 1))\n",
    "            regressor = GaussianProcessRegressor(kernel=Matern(length_scale=1, nu=1.5), random_state=0)\n",
    "            regressor.fit(x_cluster, y_cluster)\n",
    "            self.regressors.append(regressor)\n",
    "    \n",
    "    def predict(self, x_test) -> None:\n",
    "        x_test_labels = self.km.predict(x_test)\n",
    "        x_ids = np.arange(x_test.shape[0]).reshape((-1, 1))\n",
    "\n",
    "        y_clusters = []\n",
    "\n",
    "        for cluster_i in range(self.n_clusters):\n",
    "            x_cluster = x_test[x_test_labels == cluster_i]\n",
    "            x_cluster_ids = x_ids[x_test_labels == cluster_i]\n",
    "            y_cluster_mean, y_cluster_std = self.regressors[cluster_i].predict(x_cluster, return_std=True)\n",
    "            y_cluster_mean = y_cluster_mean.reshape((-1, 1))\n",
    "            y_cluster = np.concatenate([y_cluster_mean, x_cluster_ids], axis=1)\n",
    "            y_clusters.append(y_cluster)\n",
    "\n",
    "        y_test = np.concatenate(y_clusters, axis=0)\n",
    "        y_test = y_test[np.argsort(y_test[:, 1])][:, 0]\n",
    "        return y_test\n",
    "\n",
    "gpr = GPR_Predictor()\n",
    "gpr.train(x_train, y_train)\n",
    "y_test = scaler_y.inverse_transform(gpr.predict(x_test).reshape((-1, 1)))\n",
    "# y_test = gpr.predict(x_test).reshape((-1, 1))\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test, columns=[\"y\"])\n",
    "y_test_df[\"Id\"] = data_test.index.tolist()\n",
    "y_test_df = y_test_df[[\"Id\", \"y\"]]\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The epoch is 0, the loss is 1.069, the loss in validation data is 0.089\n",
      "The epoch is 1, the loss is 0.092, the loss in validation data is 0.232\n",
      "The epoch is 2, the loss is 0.227, the loss in validation data is 0.147\n",
      "The epoch is 3, the loss is 0.145, the loss in validation data is 0.039\n",
      "The epoch is 4, the loss is 0.041, the loss in validation data is 0.080\n",
      "The epoch is 5, the loss is 0.082, the loss in validation data is 0.142\n",
      "The epoch is 6, the loss is 0.145, the loss in validation data is 0.133\n",
      "The epoch is 7, the loss is 0.136, the loss in validation data is 0.075\n",
      "The epoch is 8, the loss is 0.079, the loss in validation data is 0.033\n",
      "The epoch is 9, the loss is 0.037, the loss in validation data is 0.042\n",
      "The epoch is 10, the loss is 0.044, the loss in validation data is 0.078\n",
      "The epoch is 11, the loss is 0.079, the loss in validation data is 0.089\n",
      "The epoch is 12, the loss is 0.090, the loss in validation data is 0.067\n",
      "The epoch is 13, the loss is 0.068, the loss in validation data is 0.041\n",
      "The epoch is 14, the loss is 0.044, the loss in validation data is 0.034\n",
      "The epoch is 15, the loss is 0.038, the loss in validation data is 0.044\n",
      "The epoch is 16, the loss is 0.048, the loss in validation data is 0.056\n",
      "The epoch is 17, the loss is 0.060, the loss in validation data is 0.058\n",
      "The epoch is 18, the loss is 0.063, the loss in validation data is 0.050\n",
      "The epoch is 19, the loss is 0.055, the loss in validation data is 0.038\n",
      "The epoch is 20, the loss is 0.042, the loss in validation data is 0.030\n",
      "The epoch is 21, the loss is 0.034, the loss in validation data is 0.032\n",
      "The epoch is 22, the loss is 0.035, the loss in validation data is 0.039\n",
      "The epoch is 23, the loss is 0.041, the loss in validation data is 0.043\n",
      "The epoch is 24, the loss is 0.044, the loss in validation data is 0.038\n",
      "The epoch is 25, the loss is 0.040, the loss in validation data is 0.030\n",
      "The epoch is 26, the loss is 0.032, the loss in validation data is 0.025\n",
      "The epoch is 27, the loss is 0.027, the loss in validation data is 0.027\n",
      "The epoch is 28, the loss is 0.029, the loss in validation data is 0.031\n",
      "The epoch is 29, the loss is 0.034, the loss in validation data is 0.032\n",
      "The epoch is 30, the loss is 0.034, the loss in validation data is 0.027\n",
      "The epoch is 31, the loss is 0.029, the loss in validation data is 0.022\n",
      "The epoch is 32, the loss is 0.024, the loss in validation data is 0.022\n",
      "The epoch is 33, the loss is 0.023, the loss in validation data is 0.025\n",
      "The epoch is 34, the loss is 0.026, the loss in validation data is 0.026\n",
      "The epoch is 35, the loss is 0.027, the loss in validation data is 0.023\n",
      "The epoch is 36, the loss is 0.024, the loss in validation data is 0.019\n",
      "The epoch is 37, the loss is 0.021, the loss in validation data is 0.019\n",
      "The epoch is 38, the loss is 0.020, the loss in validation data is 0.021\n",
      "The epoch is 39, the loss is 0.022, the loss in validation data is 0.021\n",
      "The epoch is 40, the loss is 0.022, the loss in validation data is 0.018\n",
      "The epoch is 41, the loss is 0.020, the loss in validation data is 0.017\n",
      "The epoch is 42, the loss is 0.018, the loss in validation data is 0.017\n",
      "The epoch is 43, the loss is 0.018, the loss in validation data is 0.018\n",
      "The epoch is 44, the loss is 0.019, the loss in validation data is 0.017\n",
      "The epoch is 45, the loss is 0.018, the loss in validation data is 0.015\n",
      "The epoch is 46, the loss is 0.016, the loss in validation data is 0.014\n",
      "The epoch is 47, the loss is 0.015, the loss in validation data is 0.015\n",
      "The epoch is 48, the loss is 0.016, the loss in validation data is 0.015\n",
      "The epoch is 49, the loss is 0.016, the loss in validation data is 0.013\n",
      "The epoch is 50, the loss is 0.014, the loss in validation data is 0.012\n",
      "The epoch is 51, the loss is 0.013, the loss in validation data is 0.013\n",
      "The epoch is 52, the loss is 0.013, the loss in validation data is 0.013\n",
      "The epoch is 53, the loss is 0.013, the loss in validation data is 0.011\n",
      "The epoch is 54, the loss is 0.012, the loss in validation data is 0.011\n",
      "The epoch is 55, the loss is 0.011, the loss in validation data is 0.011\n",
      "The epoch is 56, the loss is 0.011, the loss in validation data is 0.011\n",
      "The epoch is 57, the loss is 0.011, the loss in validation data is 0.010\n",
      "The epoch is 58, the loss is 0.010, the loss in validation data is 0.009\n",
      "The epoch is 59, the loss is 0.010, the loss in validation data is 0.009\n",
      "The epoch is 60, the loss is 0.010, the loss in validation data is 0.009\n",
      "The epoch is 61, the loss is 0.009, the loss in validation data is 0.008\n",
      "The epoch is 62, the loss is 0.008, the loss in validation data is 0.008\n",
      "The epoch is 63, the loss is 0.008, the loss in validation data is 0.008\n",
      "The epoch is 64, the loss is 0.008, the loss in validation data is 0.007\n",
      "The epoch is 65, the loss is 0.007, the loss in validation data is 0.007\n",
      "The epoch is 66, the loss is 0.007, the loss in validation data is 0.007\n",
      "The epoch is 67, the loss is 0.007, the loss in validation data is 0.006\n",
      "The epoch is 68, the loss is 0.006, the loss in validation data is 0.006\n",
      "The epoch is 69, the loss is 0.006, the loss in validation data is 0.006\n",
      "The epoch is 70, the loss is 0.006, the loss in validation data is 0.005\n",
      "The epoch is 71, the loss is 0.006, the loss in validation data is 0.005\n",
      "The epoch is 72, the loss is 0.005, the loss in validation data is 0.005\n",
      "The epoch is 73, the loss is 0.005, the loss in validation data is 0.005\n",
      "The epoch is 74, the loss is 0.005, the loss in validation data is 0.004\n",
      "The epoch is 75, the loss is 0.004, the loss in validation data is 0.004\n",
      "The epoch is 76, the loss is 0.004, the loss in validation data is 0.004\n",
      "The epoch is 77, the loss is 0.004, the loss in validation data is 0.004\n",
      "The epoch is 78, the loss is 0.004, the loss in validation data is 0.003\n",
      "The epoch is 79, the loss is 0.003, the loss in validation data is 0.003\n",
      "The epoch is 80, the loss is 0.003, the loss in validation data is 0.003\n",
      "The epoch is 81, the loss is 0.003, the loss in validation data is 0.003\n",
      "The epoch is 82, the loss is 0.003, the loss in validation data is 0.003\n",
      "The epoch is 83, the loss is 0.003, the loss in validation data is 0.003\n",
      "The epoch is 84, the loss is 0.003, the loss in validation data is 0.002\n",
      "The epoch is 85, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 86, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 87, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 88, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 89, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 90, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 91, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 92, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 93, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 94, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 95, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 96, the loss is 0.002, the loss in validation data is 0.002\n",
      "The epoch is 97, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 98, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 99, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 100, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 101, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 102, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 103, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 104, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 105, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 106, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 107, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 108, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 109, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 110, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 111, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 112, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 113, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 114, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 115, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 116, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 117, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 118, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 119, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 120, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 121, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 122, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 123, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 124, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 125, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 126, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 127, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 128, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 129, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 130, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 131, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 132, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 133, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 134, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 135, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 136, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 137, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 138, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 139, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 140, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 141, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 142, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 143, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 144, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 145, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 146, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 147, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 148, the loss is 0.001, the loss in validation data is 0.001\n",
      "The epoch is 149, the loss is 0.001, the loss in validation data is 0.001\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# preprocess data\n",
    "x_train, y_train = data_train.iloc[:, 1:].to_numpy(), data_train.iloc[:, 0].to_numpy().reshape((-1, 1))\n",
    "x_test = data_test.to_numpy()\n",
    "\n",
    "scaler_x, scaler_y = StandardScaler(), StandardScaler()\n",
    "x_train = scaler_x.fit_transform(x_train)\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "x_test = scaler_x.transform(x_test)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, shuffle=True)\n",
    "\n",
    "x_train = torch.from_numpy(x_train).to(device).float()\n",
    "y_train = torch.from_numpy(y_train).to(device).float()\n",
    "x_valid = torch.from_numpy(x_valid).to(device).float()\n",
    "y_valid = torch.from_numpy(y_valid).to(device).float()\n",
    "x_test = torch.from_numpy(x_test).to(device).float()\n",
    "\n",
    "class NN_Model(Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tanh = tanh\n",
    "        self.nn1 = Linear(10, 256, device=device)\n",
    "        self.dropout1 = Dropout(0.5)\n",
    "        self.nn2 = Linear(256, 64, device=device)\n",
    "        self.dropout2 = Dropout(0.5)\n",
    "        self.nn3 = Linear(64, 1, device=device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.tanh(self.nn1(x))\n",
    "        # output = self.dropout1(output)\n",
    "        output = self.tanh(self.nn2(output))\n",
    "        # output = self.dropout2(output)\n",
    "        output = self.nn3(output)\n",
    "        return output\n",
    "\n",
    "model = NN_Model()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(150):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_train)\n",
    "    loss = mse_loss(output, y_train)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # valid\n",
    "    valid_loss = mse_loss(model(x_valid), y_valid)\n",
    "\n",
    "    print(\"The epoch is {}, the loss is {:.03f}, the loss in validation data is {:.03f}\".format(epoch, loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>-65.592834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>460.452759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>-474.305145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>51.545864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>-126.654381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id           y\n",
       "0  10000  -65.592834\n",
       "1  10001  460.452759\n",
       "2  10002 -474.305145\n",
       "3  10003   51.545864\n",
       "4  10004 -126.654381"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = scaler_y.inverse_transform(np.array(model(x_test).to(\"cpu\").detach()))\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test, columns=[\"y\"])\n",
    "y_test_df[\"Id\"] = data_test.index.tolist()\n",
    "y_test_df = y_test_df[[\"Id\", \"y\"]]\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.to_csv(\"./Result/result_1.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
