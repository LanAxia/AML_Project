{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, r_regression\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, Linear, Dropout\n",
    "from torch.nn.functional import tanh, softmax, mse_loss, relu\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load and split data\n",
    "data_X_train = pd.read_csv('Data/X_train.csv', header=0, index_col=0)\n",
    "data_y_train = pd.read_csv('Data/y_train.csv', header=0, index_col=0)\n",
    "data_X_test = pd.read_csv('Data/X_test.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData Shape: 1212 x 832\\nData Lost: a lot\\ndata scale: large\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data info\n",
    "data_X_train.describe()\n",
    "\"\"\"\n",
    "Data Shape: 1212 x 832\n",
    "Data Lost: a lot\n",
    "data scale: large\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# transfer data to numpy\n",
    "X_train = data_X_train.to_numpy()\n",
    "y_train = data_y_train.to_numpy()\n",
    "X_test = data_X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理缺省值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 删除变化过小的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "del_columns_id_all0 = np.where(X_train.sum(axis=0) == 0)\n",
    "X_train = np.delete(X_train, del_columns_id_all0, axis=1)\n",
    "X_test = np.delete(X_test, del_columns_id_all0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 皮尔森系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "cc = r_regression(X_train, y_train.ravel())\n",
    "del_columns_id_pearson = np.where(np.absolute(cc) <= 1e-2) # 删除pearson系数小于0.01的特征\n",
    "X_train = np.delete(X_train, del_columns_id_pearson, axis=1)\n",
    "X_test = np.delete(X_test, del_columns_id_pearson, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 删减特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV\n",
    "estimator = LinearRegression()\n",
    "selector = RFECV(estimator, step=1, cv=5, scoring='r2')\n",
    "selector.fit(X_train, y_train)\n",
    "feature_ranks = selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# store the feature ranking\n",
    "# pd.DataFrame(selector.ranking_).to_csv(\"Temp/feature_ranking.csv\", header=False, index=False)\n",
    "feature_ranks = pd.read_csv(\"Temp/feature_ranking.csv\", header=None, index_col=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# choose features (top 95%)\n",
    "def select_features(x, rank, threshold=0.8):\n",
    "    drop_feature_ids = np.where(rank > int(threshold * max(rank)))\n",
    "    selected_x = np.delete(x, drop_feature_ids, axis=1)\n",
    "    return selected_x\n",
    "\n",
    "X_train = select_features(X_train, feature_ranks, 0.95)\n",
    "X_test = select_features(X_test, feature_ranks, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保留特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 200)\n"
     ]
    }
   ],
   "source": [
    "# 使用selectkbest方法选择特征\n",
    "skb = SelectKBest(k=200)\n",
    "X_train = skb.fit_transform(X_train,y_train.ravel())\n",
    "X_test = skb.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 噪声探测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([167, 207, 213, 681, 740, 805], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_rows_id_all0 = np.where(X_train.std(axis=1) >= 1.5)\n",
    "# X_train = np.delete(X_train, del_columns_id_all0, axis=1)\n",
    "del_rows_id_all0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "！！！该方法具有较高的不确定性，不能保证有效\n",
    "思路：\n",
    "    1. 以每5年为一个period，计算数据到中心点的距离\n",
    "    2. 剔除距离最大的5%的数据\n",
    "\"\"\"\n",
    "deleted_sample_ids = []\n",
    "for start_year in np.arange(y_train.min(), y_train.max() + 1, 5):\n",
    "    cluster_x_train = X_train[y_train >= start_year and y_train < start_year + 5] \n",
    "    center_point = np.mean(cluster_x_train, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.890191269931073\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_score = 0\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_score += r2_score(fold_y_valid, fold_y_pred)\n",
    "fold_score /= fold_num\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019787009919412422\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_score = 0\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = KernelRidge(kernel=\"rbf\")\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_score += r2_score(fold_y_valid, fold_y_pred)\n",
    "fold_score /= fold_num\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749308857165471\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process Regressor (Matern)\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GaussianProcessRegressor(kernel=Matern(nu=0.5, length_scale=1), random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01484695627455086\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process Regressor (RBF)\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GaussianProcessRegressor(kernel=RBF(length_scale=10), random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27278034373557075\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = SVR(kernel=\"rbf\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45761414755344837\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=0, criterion=\"squared_error\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.88352200279015\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = IsolationForest(n_estimators=100, max_features=0.6, random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5033211490279413\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = np.round(model.predict(fold_X_valid))\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4110280800135076\n"
     ]
    }
   ],
   "source": [
    "# Adaboost Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = AdaBoostRegressor(n_estimators=100, learning_rate=0.1, loss=\"square\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5046748548918308\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = xgb.XGBRegressor(n_estimators=200, max_depth=7, learning_rate=0.1, n_jobs=20)\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = np.round(model.predict(fold_X_valid))\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>771</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>773</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>774</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>775</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     y\n",
       "0      0  61.0\n",
       "1      1  77.0\n",
       "2      2  65.0\n",
       "3      3  73.0\n",
       "4      4  73.0\n",
       "..   ...   ...\n",
       "771  771  63.0\n",
       "772  772  74.0\n",
       "773  773  73.0\n",
       "774  774  69.0\n",
       "775  775  63.0\n",
       "\n",
       "[776 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(n_estimators=200, max_depth=7, learning_rate=0.1, n_jobs=20)\n",
    "model.fit(X_train, y_train.ravel())\n",
    "y_pred = np.round(model.predict(X_test))\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=[\"y\"], index=data_X_test.index).reset_index()\n",
    "y_pred_df[\"id\"] = y_pred_df[\"id\"].astype(int)\n",
    "y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df.to_csv(\"result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
