{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, Linear, Dropout\n",
    "from torch.nn.functional import tanh, softmax, mse_loss, relu\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split data\n",
    "data_X_train = pd.read_csv('Data/X_train.csv', header=0, index_col=0)\n",
    "data_y_train = pd.read_csv('Data/y_train.csv', header=0, index_col=0)\n",
    "data_X_test = pd.read_csv('Data/X_test.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData Shape: 1212 x 832\\nData Lost: a lot\\ndata scale: large\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data info\n",
    "data_X_train.describe()\n",
    "\"\"\"\n",
    "Data Shape: 1212 x 832\n",
    "Data Lost: a lot\n",
    "data scale: large\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer data to numpy\n",
    "X_train = data_X_train.to_numpy()\n",
    "y_train = data_y_train.to_numpy()\n",
    "X_test = data_X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理缺省值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_train = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV\n",
    "estimator = LinearRegression()\n",
    "selector = RFECV(estimator, step=1, cv=5, scoring='r2')\n",
    "selector.fit(X_train, y_train)\n",
    "feature_ranks = selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the feature ranking\n",
    "pd.DataFrame(selector.ranking_).to_csv(\"Temp/feature_ranking.csv\", header=False, index=False)\n",
    "feature_ranks = pd.read_csv(\"Temp/feature_ranking.csv\", header=None, index_col=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose features (top 95%)\n",
    "def select_features(x, rank, threshold=0.95):\n",
    "    drop_feature_ids = np.where(rank > int(threshold * max(rank)))\n",
    "    selected_x = np.delete(x, drop_feature_ids, axis=1)\n",
    "    return selected_x\n",
    "\n",
    "X_train = select_features(X_train, feature_ranks, 0.95)\n",
    "X_test = select_features(X_test, feature_ranks, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 噪声探测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5, 3.5, 4.5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "！！！该方法具有较高的不确定性，不能保证有效\n",
    "思路：\n",
    "    1. 以每5年为一个period，计算数据到中心点的距离\n",
    "    2. 剔除距离最大的5%的数据\n",
    "\"\"\"\n",
    "deleted_sample_ids = []\n",
    "for start_year in np.arange(y_train.min(), y_train.max() + 1, 5):\n",
    "    cluster_x_train = X_train[y_train >= start_year and y_train < start_year + 5] \n",
    "    center_point = np.mean(cluster_x_train, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
