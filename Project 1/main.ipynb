{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, r_regression\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, Linear, Dropout\n",
    "from torch.nn.functional import tanh, softmax, mse_loss, relu, sigmoid\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load and split data\n",
    "data_X_train = pd.read_csv('Data/X_train.csv', header=0, index_col=0)\n",
    "data_y_train = pd.read_csv('Data/y_train.csv', header=0, index_col=0)\n",
    "data_X_test = pd.read_csv('Data/X_test.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData Shape: 1212 x 832\\nData Lost: a lot\\ndata scale: large\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data info\n",
    "data_X_train.describe()\n",
    "\"\"\"\n",
    "Data Shape: 1212 x 832\n",
    "Data Lost: a lot\n",
    "data scale: large\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# transfer data to numpy\n",
    "X_train = data_X_train.to_numpy()\n",
    "y_train = data_y_train.to_numpy()\n",
    "X_test = data_X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "x_scalar = StandardScaler()\n",
    "X_train = x_scalar.fit_transform(X_train)\n",
    "X_test = x_scalar.transform(X_test)\n",
    "\n",
    "# y_scalar = StandardScaler()\n",
    "# y_train = y_scalar.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理缺省值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 删除变化过小的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "del_columns_id_all0 = np.where(X_train.sum(axis=0) == 0)\n",
    "X_train = np.delete(X_train, del_columns_id_all0, axis=1)\n",
    "X_test = np.delete(X_test, del_columns_id_all0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 皮尔森系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "cc = r_regression(X_train, y_train.ravel())\n",
    "del_columns_id_pearson = np.where(np.absolute(cc) <= 1e-2) # 删除pearson系数小于0.01的特征\n",
    "X_train = np.delete(X_train, del_columns_id_pearson, axis=1)\n",
    "X_test = np.delete(X_test, del_columns_id_pearson, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 删减特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV\n",
    "estimator = LinearRegression()\n",
    "selector = RFECV(estimator, step=1, cv=5, scoring='r2')\n",
    "selector.fit(X_train, y_train)\n",
    "feature_ranks = selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# store the feature ranking\n",
    "# pd.DataFrame(selector.ranking_).to_csv(\"Temp/feature_ranking.csv\", header=False, index=False)\n",
    "feature_ranks = pd.read_csv(\"Temp/feature_ranking.csv\", header=None, index_col=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# choose features (top 95%)\n",
    "def select_features(x, rank, threshold=0.8):\n",
    "    drop_feature_ids = np.where(rank > int(threshold * max(rank)))\n",
    "    selected_x = np.delete(x, drop_feature_ids, axis=1)\n",
    "    return selected_x\n",
    "\n",
    "X_train = select_features(X_train, feature_ranks, 0.95)\n",
    "X_test = select_features(X_test, feature_ranks, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保留特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 200)\n"
     ]
    }
   ],
   "source": [
    "# 使用selectkbest方法选择特征\n",
    "skb = SelectKBest(k=200)\n",
    "X_train = skb.fit_transform(X_train,y_train.ravel())\n",
    "X_test = skb.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 噪声探测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1136, 200)\n",
      "(1136, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "！！！该方法具有较高的不确定性，不能保证有效\n",
    "思路：\n",
    "    1. 以每一个实际y为单位，找出上下年龄差为5的数据\n",
    "    2. 计算该数据到这一组数据的均值的距离\n",
    "    3. 如果距离大于某一阈值，则删除该数据\n",
    "\"\"\"\n",
    "ERROR_COEFFICIENT = 2\n",
    "\n",
    "deleted_sample_ids = []\n",
    "errors = []\n",
    "for row_i in range(X_train.shape[0]):\n",
    "    X_row = X_train[row_i]\n",
    "    y_row = y_train[row_i]\n",
    "\n",
    "    sub_y_X = X_train[((y_train >= y_row - 5) & (y_train <= y_row + 5)).ravel()]\n",
    "    if sub_y_X.shape[0] > 10:\n",
    "        sub_y_X_mean = np.average(sub_y_X, axis=0)\n",
    "        sub_y_X_std = np.std(sub_y_X, axis=0)\n",
    "        sub_y_X_error = (X_row > sub_y_X_mean + ERROR_COEFFICIENT * sub_y_X_std) | (X_row < sub_y_X_mean - ERROR_COEFFICIENT * sub_y_X_std)\n",
    "        errors.append(sub_y_X_error.sum())\n",
    "        if sub_y_X_error.sum() > X_train.shape[1] * 0.15:\n",
    "            deleted_sample_ids.append(row_i)\n",
    "    else:\n",
    "        continue\n",
    "X_train = np.delete(X_train, deleted_sample_ids, axis=0)\n",
    "y_train = np.delete(y_train, deleted_sample_ids, axis=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169, 200)\n",
      "(1169, 1)\n"
     ]
    }
   ],
   "source": [
    "# 另一种方法 用四分位数解决outlier的问题\n",
    "IQR_threshold = 15\n",
    "IQR_efficient = 2\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "q1 = X_train.quantile(0.25)\n",
    "q3 = X_train.quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "mask = ((X_train < (q1 - IQR_efficient * IQR)) | (X_train > (q3 + IQR_efficient * IQR)))\n",
    "\n",
    "# outliers = X_train[mask]\n",
    "# outliers\n",
    "mask = mask.sum(axis=1) > IQR_threshold\n",
    "outliers = X_train[mask]\n",
    "X_train = X_train[~mask].to_numpy()\n",
    "y_train = y_train[~mask]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.890191269931073\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_score = 0\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_score += r2_score(fold_y_valid, fold_y_pred)\n",
    "fold_score /= fold_num\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019787009919412422\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_score = 0\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = KernelRidge(kernel=\"rbf\")\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_score += r2_score(fold_y_valid, fold_y_pred)\n",
    "fold_score /= fold_num\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749308857165471\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process Regressor (Matern)\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GaussianProcessRegressor(kernel=Matern(nu=0.5, length_scale=1), random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01484695627455086\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process Regressor (RBF)\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GaussianProcessRegressor(kernel=RBF(length_scale=10), random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27278034373557075\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = SVR(kernel=\"rbf\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45761414755344837\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=0, criterion=\"squared_error\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.88352200279015\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = IsolationForest(n_estimators=100, max_features=0.6, random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6455286476185035\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = np.round(model.predict(fold_X_valid))\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4110280800135076\n"
     ]
    }
   ],
   "source": [
    "# Adaboost Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = AdaBoostRegressor(n_estimators=100, learning_rate=0.1, loss=\"square\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6628370028029413\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = xgb.XGBRegressor(n_estimators=150, max_depth=5, learning_rate=0.11, n_jobs=20)\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = np.round(model.predict(fold_X_valid))\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.nn1 = Linear(200, 256)\n",
    "        # self.dropout1 = Dropout(0.5)\n",
    "        self.nn2 = Linear(256, 64)\n",
    "        # self.dropout2 = Dropout(0.5)\n",
    "        self.nn3 = Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = sigmoid(self.nn1(x))\n",
    "        # output = self.dropout1(output)\n",
    "        output = sigmoid(self.nn2(output))\n",
    "        # output = self.dropout2(output)\n",
    "        output = self.nn3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The epoch is 0, the loss is 5015.557, the loss in validation data is 1451.557\n",
      "The epoch is 1, the loss is 1441.213, the loss in validation data is 4181.361\n",
      "The epoch is 2, the loss is 4220.127, the loss in validation data is 1434.339\n",
      "The epoch is 3, the loss is 1460.927, the loss in validation data is 1288.183\n",
      "The epoch is 4, the loss is 1279.185, the loss in validation data is 2626.787\n",
      "The epoch is 5, the loss is 2609.954, the loss in validation data is 121.457\n",
      "The epoch is 6, the loss is 132.830, the loss in validation data is 2393.577\n",
      "The epoch is 7, the loss is 2425.821, the loss in validation data is 394.511\n",
      "The epoch is 8, the loss is 411.596, the loss in validation data is 1305.913\n",
      "The epoch is 9, the loss is 1296.785, the loss in validation data is 1196.299\n",
      "The epoch is 10, the loss is 1187.971, the loss in validation data is 301.476\n",
      "The epoch is 11, the loss is 317.130, the loss in validation data is 1445.790\n",
      "The epoch is 12, the loss is 1472.476, the loss in validation data is 103.029\n",
      "The epoch is 13, the loss is 113.536, the loss in validation data is 1068.977\n",
      "The epoch is 14, the loss is 1061.629, the loss in validation data is 472.679\n",
      "The epoch is 15, the loss is 471.141, the loss in validation data is 415.838\n",
      "The epoch is 16, the loss is 433.219, the loss in validation data is 777.286\n",
      "The epoch is 17, the loss is 798.708, the loss in validation data is 98.160\n",
      "The epoch is 18, the loss is 104.534, the loss in validation data is 756.676\n",
      "The epoch is 19, the loss is 752.041, the loss in validation data is 175.402\n",
      "The epoch is 20, the loss is 178.915, the loss in validation data is 418.215\n",
      "The epoch is 21, the loss is 435.629, the loss in validation data is 380.979\n",
      "The epoch is 22, the loss is 397.871, the loss in validation data is 153.318\n",
      "The epoch is 23, the loss is 157.443, the loss in validation data is 482.481\n",
      "The epoch is 24, the loss is 480.821, the loss in validation data is 90.112\n",
      "The epoch is 25, the loss is 97.107, the loss in validation data is 350.663\n",
      "The epoch is 26, the loss is 367.105, the loss in validation data is 183.501\n",
      "The epoch is 27, the loss is 196.783, the loss in validation data is 186.574\n",
      "The epoch is 28, the loss is 189.806, the loss in validation data is 288.934\n",
      "The epoch is 29, the loss is 290.083, the loss in validation data is 86.426\n",
      "The epoch is 30, the loss is 95.602, the loss in validation data is 263.427\n",
      "The epoch is 31, the loss is 278.409, the loss in validation data is 104.769\n",
      "The epoch is 32, the loss is 115.372, the loss in validation data is 186.522\n",
      "The epoch is 33, the loss is 189.755, the loss in validation data is 173.546\n",
      "The epoch is 34, the loss is 177.107, the loss in validation data is 100.419\n",
      "The epoch is 35, the loss is 110.776, the loss in validation data is 187.871\n",
      "The epoch is 36, the loss is 201.261, the loss in validation data is 84.174\n",
      "The epoch is 37, the loss is 92.935, the loss in validation data is 166.042\n",
      "The epoch is 38, the loss is 169.804, the loss in validation data is 115.226\n",
      "The epoch is 39, the loss is 120.706, the loss in validation data is 108.970\n",
      "The epoch is 40, the loss is 119.790, the loss in validation data is 135.381\n",
      "The epoch is 41, the loss is 147.272, the loss in validation data is 85.190\n",
      "The epoch is 42, the loss is 92.799, the loss in validation data is 139.852\n",
      "The epoch is 43, the loss is 144.400, the loss in validation data is 91.131\n",
      "The epoch is 44, the loss is 98.031, the loss in validation data is 108.757\n",
      "The epoch is 45, the loss is 119.565, the loss in validation data is 104.827\n",
      "The epoch is 46, the loss is 115.433, the loss in validation data is 90.157\n",
      "The epoch is 47, the loss is 97.147, the loss in validation data is 117.059\n",
      "The epoch is 48, the loss is 122.458, the loss in validation data is 84.007\n",
      "The epoch is 49, the loss is 91.882, the loss in validation data is 103.241\n",
      "The epoch is 50, the loss is 113.761, the loss in validation data is 90.029\n",
      "The epoch is 51, the loss is 99.616, the loss in validation data is 92.904\n",
      "The epoch is 52, the loss is 99.655, the loss in validation data is 100.978\n",
      "The epoch is 53, the loss is 107.178, the loss in validation data is 83.441\n",
      "The epoch is 54, the loss is 91.924, the loss in validation data is 96.389\n",
      "The epoch is 55, the loss is 106.487, the loss in validation data is 84.469\n",
      "The epoch is 56, the loss is 93.302, the loss in validation data is 92.770\n",
      "The epoch is 57, the loss is 99.531, the loss in validation data is 91.323\n",
      "The epoch is 58, the loss is 98.206, the loss in validation data is 84.361\n",
      "The epoch is 59, the loss is 93.169, the loss in validation data is 90.606\n",
      "The epoch is 60, the loss is 100.247, the loss in validation data is 83.301\n",
      "The epoch is 61, the loss is 91.618, the loss in validation data is 90.925\n",
      "The epoch is 62, the loss is 97.844, the loss in validation data is 86.346\n",
      "The epoch is 63, the loss is 93.771, the loss in validation data is 84.934\n",
      "The epoch is 64, the loss is 93.866, the loss in validation data is 86.708\n",
      "The epoch is 65, the loss is 95.923, the loss in validation data is 83.656\n",
      "The epoch is 66, the loss is 91.653, the loss in validation data is 88.616\n",
      "The epoch is 67, the loss is 95.761, the loss in validation data is 84.189\n",
      "The epoch is 68, the loss is 92.014, the loss in validation data is 84.891\n",
      "The epoch is 69, the loss is 93.814, the loss in validation data is 84.544\n",
      "The epoch is 70, the loss is 93.395, the loss in validation data is 84.182\n",
      "The epoch is 71, the loss is 92.009, the loss in validation data is 86.598\n",
      "The epoch is 72, the loss is 93.987, the loss in validation data is 83.455\n",
      "The epoch is 73, the loss is 91.553, the loss in validation data is 84.486\n",
      "The epoch is 74, the loss is 93.324, the loss in validation data is 83.589\n",
      "The epoch is 75, the loss is 92.152, the loss in validation data is 84.440\n",
      "The epoch is 76, the loss is 92.202, the loss in validation data is 85.146\n",
      "The epoch is 77, the loss is 92.764, the loss in validation data is 83.302\n",
      "The epoch is 78, the loss is 91.569, the loss in validation data is 84.012\n",
      "The epoch is 79, the loss is 92.728, the loss in validation data is 83.312\n",
      "The epoch is 80, the loss is 91.663, the loss in validation data is 84.414\n",
      "The epoch is 81, the loss is 92.183, the loss in validation data is 84.241\n",
      "The epoch is 82, the loss is 92.052, the loss in validation data is 83.314\n",
      "The epoch is 83, the loss is 91.670, the loss in validation data is 83.638\n",
      "The epoch is 84, the loss is 92.223, the loss in validation data is 83.330\n",
      "The epoch is 85, the loss is 91.537, the loss in validation data is 84.225\n",
      "The epoch is 86, the loss is 92.040, the loss in validation data is 83.739\n",
      "The epoch is 87, the loss is 91.703, the loss in validation data is 83.335\n",
      "The epoch is 88, the loss is 91.724, the loss in validation data is 83.414\n",
      "The epoch is 89, the loss is 91.877, the loss in validation data is 83.426\n",
      "The epoch is 90, the loss is 91.543, the loss in validation data is 83.989\n",
      "The epoch is 91, the loss is 91.870, the loss in validation data is 83.491\n",
      "The epoch is 92, the loss is 91.567, the loss in validation data is 83.332\n",
      "The epoch is 93, the loss is 91.717, the loss in validation data is 83.316\n",
      "The epoch is 94, the loss is 91.677, the loss in validation data is 83.501\n",
      "The epoch is 95, the loss is 91.572, the loss in validation data is 83.776\n",
      "The epoch is 96, the loss is 91.726, the loss in validation data is 83.380\n",
      "The epoch is 97, the loss is 91.533, the loss in validation data is 83.316\n",
      "The epoch is 98, the loss is 91.676, the loss in validation data is 83.300\n",
      "The epoch is 99, the loss is 91.579, the loss in validation data is 83.533\n",
      "The epoch is 100, the loss is 91.587, the loss in validation data is 83.613\n",
      "The epoch is 101, the loss is 91.628, the loss in validation data is 83.335\n",
      "The epoch is 102, the loss is 91.535, the loss in validation data is 83.302\n",
      "The epoch is 103, the loss is 91.627, the loss in validation data is 83.321\n",
      "The epoch is 104, the loss is 91.541, the loss in validation data is 83.528\n",
      "The epoch is 105, the loss is 91.584, the loss in validation data is 83.502\n",
      "The epoch is 106, the loss is 91.572, the loss in validation data is 83.319\n",
      "The epoch is 107, the loss is 91.543, the loss in validation data is 83.299\n",
      "The epoch is 108, the loss is 91.586, the loss in validation data is 83.353\n",
      "The epoch is 109, the loss is 91.532, the loss in validation data is 83.503\n",
      "The epoch is 110, the loss is 91.572, the loss in validation data is 83.431\n",
      "The epoch is 111, the loss is 91.545, the loss in validation data is 83.314\n",
      "The epoch is 112, the loss is 91.547, the loss in validation data is 83.306\n",
      "The epoch is 113, the loss is 91.559, the loss in validation data is 83.378\n",
      "The epoch is 114, the loss is 91.533, the loss in validation data is 83.470\n",
      "The epoch is 115, the loss is 91.559, the loss in validation data is 83.389\n",
      "The epoch is 116, the loss is 91.534, the loss in validation data is 83.315\n",
      "The epoch is 117, the loss is 91.547, the loss in validation data is 83.319\n",
      "The epoch is 118, the loss is 91.543, the loss in validation data is 83.393\n",
      "The epoch is 119, the loss is 91.535, the loss in validation data is 83.438\n",
      "The epoch is 120, the loss is 91.547, the loss in validation data is 83.365\n",
      "The epoch is 121, the loss is 91.532, the loss in validation data is 83.319\n",
      "The epoch is 122, the loss is 91.543, the loss in validation data is 83.334\n",
      "The epoch is 123, the loss is 91.535, the loss in validation data is 83.399\n",
      "The epoch is 124, the loss is 91.536, the loss in validation data is 83.412\n",
      "The epoch is 125, the loss is 91.539, the loss in validation data is 83.352\n",
      "The epoch is 126, the loss is 91.532, the loss in validation data is 83.325\n",
      "The epoch is 127, the loss is 91.539, the loss in validation data is 83.348\n",
      "The epoch is 128, the loss is 91.532, the loss in validation data is 83.398\n",
      "The epoch is 129, the loss is 91.536, the loss in validation data is 83.392\n",
      "The epoch is 130, the loss is 91.535, the loss in validation data is 83.346\n",
      "The epoch is 131, the loss is 91.532, the loss in validation data is 83.332\n",
      "The epoch is 132, the loss is 91.536, the loss in validation data is 83.359\n",
      "The epoch is 133, the loss is 91.531, the loss in validation data is 83.393\n",
      "The epoch is 134, the loss is 91.535, the loss in validation data is 83.378\n",
      "The epoch is 135, the loss is 91.532, the loss in validation data is 83.344\n",
      "The epoch is 136, the loss is 91.533, the loss in validation data is 83.340\n",
      "The epoch is 137, the loss is 91.534, the loss in validation data is 83.366\n",
      "The epoch is 138, the loss is 91.532, the loss in validation data is 83.386\n",
      "The epoch is 139, the loss is 91.534, the loss in validation data is 83.368\n",
      "The epoch is 140, the loss is 91.532, the loss in validation data is 83.345\n",
      "The epoch is 141, the loss is 91.533, the loss in validation data is 83.347\n",
      "The epoch is 142, the loss is 91.532, the loss in validation data is 83.370\n",
      "The epoch is 143, the loss is 91.532, the loss in validation data is 83.380\n",
      "The epoch is 144, the loss is 91.533, the loss in validation data is 83.362\n",
      "The epoch is 145, the loss is 91.531, the loss in validation data is 83.347\n",
      "The epoch is 146, the loss is 91.532, the loss in validation data is 83.353\n",
      "The epoch is 147, the loss is 91.532, the loss in validation data is 83.371\n",
      "The epoch is 148, the loss is 91.532, the loss in validation data is 83.374\n",
      "The epoch is 149, the loss is 91.532, the loss in validation data is 83.358\n",
      "The epoch is 0, the loss is 4978.752, the loss in validation data is 1124.233\n",
      "The epoch is 1, the loss is 1138.324, the loss in validation data is 4263.960\n",
      "The epoch is 2, the loss is 4217.103, the loss in validation data is 1407.438\n",
      "The epoch is 3, the loss is 1377.887, the loss in validation data is 988.960\n",
      "The epoch is 4, the loss is 1002.077, the loss in validation data is 2457.960\n",
      "The epoch is 5, the loss is 2483.150, the loss in validation data is 95.270\n",
      "The epoch is 6, the loss is 88.700, the loss in validation data is 2077.062\n",
      "The epoch is 7, the loss is 2042.159, the loss in validation data is 688.937\n",
      "The epoch is 8, the loss is 667.036, the loss in validation data is 782.843\n",
      "The epoch is 9, the loss is 793.591, the loss in validation data is 1385.568\n",
      "The epoch is 10, the loss is 1402.573, the loss in validation data is 113.234\n",
      "The epoch is 11, the loss is 104.295, the loss in validation data is 1328.593\n",
      "The epoch is 12, the loss is 1299.754, the loss in validation data is 347.702\n",
      "The epoch is 13, the loss is 331.267, the loss in validation data is 598.055\n",
      "The epoch is 14, the loss is 606.353, the loss in validation data is 781.937\n",
      "The epoch is 15, the loss is 792.674, the loss in validation data is 133.428\n",
      "The epoch is 16, the loss is 123.247, the loss in validation data is 847.842\n",
      "The epoch is 17, the loss is 823.962, the loss in validation data is 193.718\n",
      "The epoch is 18, the loss is 181.128, the loss in validation data is 448.068\n",
      "The epoch is 19, the loss is 454.019, the loss in validation data is 450.118\n",
      "The epoch is 20, the loss is 456.104, the loss in validation data is 143.661\n",
      "The epoch is 21, the loss is 132.980, the loss in validation data is 545.985\n",
      "The epoch is 22, the loss is 526.105, the loss in validation data is 128.911\n",
      "The epoch is 23, the loss is 118.972, the loss in validation data is 334.272\n",
      "The epoch is 24, the loss is 338.079, the loss in validation data is 272.395\n",
      "The epoch is 25, the loss is 274.816, the loss in validation data is 144.354\n",
      "The epoch is 26, the loss is 133.641, the loss in validation data is 360.390\n",
      "The epoch is 27, the loss is 343.701, the loss in validation data is 104.309\n",
      "The epoch is 28, the loss is 96.154, the loss in validation data is 252.191\n",
      "The epoch is 29, the loss is 254.108, the loss in validation data is 179.971\n",
      "The epoch is 30, the loss is 179.746, the loss in validation data is 139.121\n",
      "The epoch is 31, the loss is 128.655, the loss in validation data is 248.515\n",
      "The epoch is 32, the loss is 234.342, the loss in validation data is 96.503\n",
      "The epoch is 33, the loss is 89.510, the loss in validation data is 195.343\n",
      "The epoch is 34, the loss is 195.635, the loss in validation data is 133.552\n",
      "The epoch is 35, the loss is 131.388, the loss in validation data is 131.331\n",
      "The epoch is 36, the loss is 121.261, the loss in validation data is 182.337\n",
      "The epoch is 37, the loss is 170.128, the loss in validation data is 94.919\n",
      "The epoch is 38, the loss is 88.649, the loss in validation data is 157.307\n",
      "The epoch is 39, the loss is 156.228, the loss in validation data is 111.226\n",
      "The epoch is 40, the loss is 107.658, the loss in validation data is 123.231\n",
      "The epoch is 41, the loss is 113.621, the loss in validation data is 143.897\n",
      "The epoch is 42, the loss is 133.205, the loss in validation data is 95.152\n",
      "The epoch is 43, the loss is 89.303, the loss in validation data is 132.625\n",
      "The epoch is 44, the loss is 130.413, the loss in validation data is 101.088\n",
      "The epoch is 45, the loss is 96.518, the loss in validation data is 116.013\n",
      "The epoch is 46, the loss is 106.872, the loss in validation data is 121.960\n",
      "The epoch is 47, the loss is 112.428, the loss in validation data is 95.601\n",
      "The epoch is 48, the loss is 89.967, the loss in validation data is 117.061\n",
      "The epoch is 49, the loss is 113.923, the loss in validation data is 96.854\n",
      "The epoch is 50, the loss is 91.581, the loss in validation data is 110.133\n",
      "The epoch is 51, the loss is 101.439, the loss in validation data is 109.652\n",
      "The epoch is 52, the loss is 100.998, the loss in validation data is 95.828\n",
      "The epoch is 53, the loss is 90.275, the loss in validation data is 107.515\n",
      "The epoch is 54, the loss is 103.631, the loss in validation data is 95.320\n",
      "The epoch is 55, the loss is 89.563, the loss in validation data is 105.623\n",
      "The epoch is 56, the loss is 97.334, the loss in validation data is 102.859\n",
      "The epoch is 57, the loss is 94.863, the loss in validation data is 95.819\n",
      "The epoch is 58, the loss is 90.263, the loss in validation data is 101.825\n",
      "The epoch is 59, the loss is 97.348, the loss in validation data is 94.919\n",
      "The epoch is 60, the loss is 88.839, the loss in validation data is 102.312\n",
      "The epoch is 61, the loss is 94.379, the loss in validation data is 99.167\n",
      "The epoch is 62, the loss is 91.658, the loss in validation data is 95.669\n",
      "The epoch is 63, the loss is 90.061, the loss in validation data is 98.536\n",
      "The epoch is 64, the loss is 93.591, the loss in validation data is 94.929\n",
      "The epoch is 65, the loss is 88.639, the loss in validation data is 99.958\n",
      "The epoch is 66, the loss is 92.331, the loss in validation data is 97.188\n",
      "The epoch is 67, the loss is 90.036, the loss in validation data is 95.470\n",
      "The epoch is 68, the loss is 89.783, the loss in validation data is 96.700\n",
      "The epoch is 69, the loss is 91.391, the loss in validation data is 95.040\n",
      "The epoch is 70, the loss is 88.621, the loss in validation data is 98.327\n",
      "The epoch is 71, the loss is 90.957, the loss in validation data is 96.138\n",
      "The epoch is 72, the loss is 89.244, the loss in validation data is 95.280\n",
      "The epoch is 73, the loss is 89.504, the loss in validation data is 95.720\n",
      "The epoch is 74, the loss is 90.130, the loss in validation data is 95.141\n",
      "The epoch is 75, the loss is 88.647, the loss in validation data is 97.218\n",
      "The epoch is 76, the loss is 90.059, the loss in validation data is 95.585\n",
      "The epoch is 77, the loss is 88.874, the loss in validation data is 95.127\n",
      "The epoch is 78, the loss is 89.261, the loss in validation data is 95.227\n",
      "The epoch is 79, the loss is 89.422, the loss in validation data is 95.201\n",
      "The epoch is 80, the loss is 88.670, the loss in validation data is 96.474\n",
      "The epoch is 81, the loss is 89.488, the loss in validation data is 95.294\n",
      "The epoch is 82, the loss is 88.712, the loss in validation data is 95.018\n",
      "The epoch is 83, the loss is 89.067, the loss in validation data is 95.002\n",
      "The epoch is 84, the loss is 89.034, the loss in validation data is 95.223\n",
      "The epoch is 85, the loss is 88.679, the loss in validation data is 95.979\n",
      "The epoch is 86, the loss is 89.133, the loss in validation data is 95.141\n",
      "The epoch is 87, the loss is 88.647, the loss in validation data is 94.950\n",
      "The epoch is 88, the loss is 88.922, the loss in validation data is 94.915\n",
      "The epoch is 89, the loss is 88.827, the loss in validation data is 95.219\n",
      "The epoch is 90, the loss is 88.678, the loss in validation data is 95.653\n",
      "The epoch is 91, the loss is 88.916, the loss in validation data is 95.059\n",
      "The epoch is 92, the loss is 88.624, the loss in validation data is 94.913\n",
      "The epoch is 93, the loss is 88.818, the loss in validation data is 94.897\n",
      "The epoch is 94, the loss is 88.719, the loss in validation data is 95.200\n",
      "The epoch is 95, the loss is 88.670, the loss in validation data is 95.437\n",
      "The epoch is 96, the loss is 88.787, the loss in validation data is 95.016\n",
      "The epoch is 97, the loss is 88.618, the loss in validation data is 94.899\n",
      "The epoch is 98, the loss is 88.746, the loss in validation data is 94.908\n",
      "The epoch is 99, the loss is 88.665, the loss in validation data is 95.174\n",
      "The epoch is 100, the loss is 88.659, the loss in validation data is 95.294\n",
      "The epoch is 101, the loss is 88.712, the loss in validation data is 94.992\n",
      "The epoch is 102, the loss is 88.618, the loss in validation data is 94.899\n",
      "The epoch is 103, the loss is 88.699, the loss in validation data is 94.929\n",
      "The epoch is 104, the loss is 88.638, the loss in validation data is 95.147\n",
      "The epoch is 105, the loss is 88.649, the loss in validation data is 95.199\n",
      "The epoch is 106, the loss is 88.669, the loss in validation data is 94.980\n",
      "The epoch is 107, the loss is 88.619, the loss in validation data is 94.907\n",
      "The epoch is 108, the loss is 88.667, the loss in validation data is 94.951\n",
      "The epoch is 109, the loss is 88.626, the loss in validation data is 95.121\n",
      "The epoch is 110, the loss is 88.640, the loss in validation data is 95.135\n",
      "The epoch is 111, the loss is 88.645, the loss in validation data is 94.974\n",
      "The epoch is 112, the loss is 88.620, the loss in validation data is 94.920\n",
      "The epoch is 113, the loss is 88.648, the loss in validation data is 94.969\n",
      "The epoch is 114, the loss is 88.621, the loss in validation data is 95.098\n",
      "The epoch is 115, the loss is 88.633, the loss in validation data is 95.092\n",
      "The epoch is 116, the loss is 88.632, the loss in validation data is 94.973\n",
      "The epoch is 117, the loss is 88.620, the loss in validation data is 94.933\n",
      "The epoch is 118, the loss is 88.635, the loss in validation data is 94.983\n",
      "The epoch is 119, the loss is 88.619, the loss in validation data is 95.078\n",
      "The epoch is 120, the loss is 88.628, the loss in validation data is 95.062\n",
      "The epoch is 121, the loss is 88.625, the loss in validation data is 94.973\n",
      "The epoch is 122, the loss is 88.620, the loss in validation data is 94.946\n",
      "The epoch is 123, the loss is 88.628, the loss in validation data is 94.993\n",
      "The epoch is 124, the loss is 88.618, the loss in validation data is 95.062\n",
      "The epoch is 125, the loss is 88.625, the loss in validation data is 95.042\n",
      "The epoch is 126, the loss is 88.621, the loss in validation data is 94.975\n",
      "The epoch is 127, the loss is 88.619, the loss in validation data is 94.958\n",
      "The epoch is 128, the loss is 88.623, the loss in validation data is 94.999\n",
      "The epoch is 129, the loss is 88.618, the loss in validation data is 95.049\n",
      "The epoch is 130, the loss is 88.622, the loss in validation data is 95.028\n",
      "The epoch is 131, the loss is 88.619, the loss in validation data is 94.978\n",
      "The epoch is 132, the loss is 88.619, the loss in validation data is 94.968\n",
      "The epoch is 133, the loss is 88.621, the loss in validation data is 95.004\n",
      "The epoch is 134, the loss is 88.618, the loss in validation data is 95.038\n",
      "The epoch is 135, the loss is 88.620, the loss in validation data is 95.019\n",
      "The epoch is 136, the loss is 88.618, the loss in validation data is 94.981\n",
      "The epoch is 137, the loss is 88.619, the loss in validation data is 94.976\n",
      "The epoch is 138, the loss is 88.619, the loss in validation data is 95.006\n",
      "The epoch is 139, the loss is 88.618, the loss in validation data is 95.030\n",
      "The epoch is 140, the loss is 88.619, the loss in validation data is 95.012\n",
      "The epoch is 141, the loss is 88.618, the loss in validation data is 94.984\n",
      "The epoch is 142, the loss is 88.618, the loss in validation data is 94.983\n",
      "The epoch is 143, the loss is 88.619, the loss in validation data is 95.007\n",
      "The epoch is 144, the loss is 88.618, the loss in validation data is 95.023\n",
      "The epoch is 145, the loss is 88.619, the loss in validation data is 95.008\n",
      "The epoch is 146, the loss is 88.618, the loss in validation data is 94.987\n",
      "The epoch is 147, the loss is 88.618, the loss in validation data is 94.988\n",
      "The epoch is 148, the loss is 88.618, the loss in validation data is 95.007\n",
      "The epoch is 149, the loss is 88.618, the loss in validation data is 95.018\n",
      "The epoch is 0, the loss is 4961.326, the loss in validation data is 1152.172\n",
      "The epoch is 1, the loss is 1128.010, the loss in validation data is 5425.887\n",
      "The epoch is 2, the loss is 5481.947, the loss in validation data is 685.255\n",
      "The epoch is 3, the loss is 704.531, the loss in validation data is 2206.831\n",
      "The epoch is 4, the loss is 2172.352, the loss in validation data is 1856.946\n",
      "The epoch is 5, the loss is 1825.503, the loss in validation data is 608.098\n",
      "The epoch is 6, the loss is 626.183, the loss in validation data is 2304.912\n",
      "The epoch is 7, the loss is 2341.562, the loss in validation data is 90.107\n",
      "The epoch is 8, the loss is 90.164, the loss in validation data is 1962.220\n",
      "The epoch is 9, the loss is 1929.834, the loss in validation data is 429.222\n",
      "The epoch is 10, the loss is 415.819, the loss in validation data is 1017.257\n",
      "The epoch is 11, the loss is 1041.217, the loss in validation data is 937.771\n",
      "The epoch is 12, the loss is 960.710, the loss in validation data is 328.186\n",
      "The epoch is 13, the loss is 317.062, the loss in validation data is 1206.290\n",
      "The epoch is 14, the loss is 1181.436, the loss in validation data is 90.488\n",
      "The epoch is 15, the loss is 90.387, the loss in validation data is 934.779\n",
      "The epoch is 16, the loss is 957.679, the loss in validation data is 254.907\n",
      "The epoch is 17, the loss is 265.419, the loss in validation data is 538.775\n",
      "The epoch is 18, the loss is 523.260, the loss in validation data is 541.161\n",
      "The epoch is 19, the loss is 525.603, the loss in validation data is 177.366\n",
      "The epoch is 20, the loss is 185.214, the loss in validation data is 600.148\n",
      "The epoch is 21, the loss is 618.100, the loss in validation data is 89.950\n",
      "The epoch is 22, the loss is 91.180, the loss in validation data is 513.491\n",
      "The epoch is 23, the loss is 498.438, the loss in validation data is 190.666\n",
      "The epoch is 24, the loss is 183.661, the loss in validation data is 275.631\n",
      "The epoch is 25, the loss is 286.741, the loss in validation data is 295.675\n",
      "The epoch is 26, the loss is 307.332, the loss in validation data is 133.888\n",
      "The epoch is 27, the loss is 129.476, the loss in validation data is 356.872\n",
      "The epoch is 28, the loss is 345.058, the loss in validation data is 91.974\n",
      "The epoch is 29, the loss is 91.440, the loss in validation data is 270.915\n",
      "The epoch is 30, the loss is 281.892, the loss in validation data is 133.857\n",
      "The epoch is 31, the loss is 139.633, the loss in validation data is 185.869\n",
      "The epoch is 32, the loss is 179.047, the loss in validation data is 205.702\n",
      "The epoch is 33, the loss is 198.146, the loss in validation data is 102.684\n",
      "The epoch is 34, the loss is 106.148, the loss in validation data is 204.095\n",
      "The epoch is 35, the loss is 212.960, the loss in validation data is 90.024\n",
      "The epoch is 36, the loss is 91.293, the loss in validation data is 186.833\n",
      "The epoch is 37, the loss is 179.974, the loss in validation data is 119.637\n",
      "The epoch is 38, the loss is 116.121, the loss in validation data is 124.926\n",
      "The epoch is 39, the loss is 130.161, the loss in validation data is 137.683\n",
      "The epoch is 40, the loss is 143.674, the loss in validation data is 98.059\n",
      "The epoch is 41, the loss is 96.498, the loss in validation data is 154.654\n",
      "The epoch is 42, the loss is 149.165, the loss in validation data is 91.372\n",
      "The epoch is 43, the loss is 90.992, the loss in validation data is 126.747\n",
      "The epoch is 44, the loss is 132.097, the loss in validation data is 100.440\n",
      "The epoch is 45, the loss is 103.657, the loss in validation data is 110.898\n",
      "The epoch is 46, the loss is 108.041, the loss in validation data is 120.118\n",
      "The epoch is 47, the loss is 116.568, the loss in validation data is 90.939\n",
      "The epoch is 48, the loss is 92.559, the loss in validation data is 113.946\n",
      "The epoch is 49, the loss is 118.412, the loss in validation data is 89.651\n",
      "The epoch is 50, the loss is 90.689, the loss in validation data is 112.648\n",
      "The epoch is 51, the loss is 109.649, the loss in validation data is 98.743\n",
      "The epoch is 52, the loss is 97.095, the loss in validation data is 95.501\n",
      "The epoch is 53, the loss is 98.065, the loss in validation data is 99.953\n",
      "The epoch is 54, the loss is 103.114, the loss in validation data is 91.350\n",
      "The epoch is 55, the loss is 90.976, the loss in validation data is 106.044\n",
      "The epoch is 56, the loss is 103.612, the loss in validation data is 90.579\n",
      "The epoch is 57, the loss is 90.445, the loss in validation data is 96.440\n",
      "The epoch is 58, the loss is 99.145, the loss in validation data is 91.803\n",
      "The epoch is 59, the loss is 93.661, the loss in validation data is 94.644\n",
      "The epoch is 60, the loss is 93.583, the loss in validation data is 98.006\n",
      "The epoch is 61, the loss is 96.451, the loss in validation data is 89.491\n",
      "The epoch is 62, the loss is 90.352, the loss in validation data is 94.160\n",
      "The epoch is 63, the loss is 96.503, the loss in validation data is 89.463\n",
      "The epoch is 64, the loss is 90.270, the loss in validation data is 95.427\n",
      "The epoch is 65, the loss is 94.240, the loss in validation data is 92.536\n",
      "The epoch is 66, the loss is 91.874, the loss in validation data is 90.218\n",
      "The epoch is 67, the loss is 91.576, the loss in validation data is 91.405\n",
      "The epoch is 68, the loss is 93.160, the loss in validation data is 90.005\n",
      "The epoch is 69, the loss is 90.111, the loss in validation data is 94.053\n",
      "The epoch is 70, the loss is 93.094, the loss in validation data is 90.087\n",
      "The epoch is 71, the loss is 90.154, the loss in validation data is 90.487\n",
      "The epoch is 72, the loss is 91.953, the loss in validation data is 89.803\n",
      "The epoch is 73, the loss is 90.948, the loss in validation data is 90.934\n",
      "The epoch is 74, the loss is 90.682, the loss in validation data is 92.103\n",
      "The epoch is 75, the loss is 91.537, the loss in validation data is 89.463\n",
      "The epoch is 76, the loss is 90.021, the loss in validation data is 90.139\n",
      "The epoch is 77, the loss is 91.462, the loss in validation data is 89.439\n",
      "The epoch is 78, the loss is 90.080, the loss in validation data is 91.231\n",
      "The epoch is 79, the loss is 90.890, the loss in validation data is 90.620\n",
      "The epoch is 80, the loss is 90.471, the loss in validation data is 89.467\n",
      "The epoch is 81, the loss is 90.285, the loss in validation data is 89.680\n",
      "The epoch is 82, the loss is 90.739, the loss in validation data is 89.694\n",
      "The epoch is 83, the loss is 89.989, the loss in validation data is 90.935\n",
      "The epoch is 84, the loss is 90.682, the loss in validation data is 89.834\n",
      "The epoch is 85, the loss is 90.035, the loss in validation data is 89.509\n",
      "The epoch is 86, the loss is 90.397, the loss in validation data is 89.451\n",
      "The epoch is 87, the loss is 90.227, the loss in validation data is 90.001\n",
      "The epoch is 88, the loss is 90.109, the loss in validation data is 90.425\n",
      "The epoch is 89, the loss is 90.348, the loss in validation data is 89.534\n",
      "The epoch is 90, the loss is 89.978, the loss in validation data is 89.476\n",
      "The epoch is 91, the loss is 90.310, the loss in validation data is 89.474\n",
      "The epoch is 92, the loss is 90.008, the loss in validation data is 90.115\n",
      "The epoch is 93, the loss is 90.168, the loss in validation data is 89.985\n",
      "The epoch is 94, the loss is 90.102, the loss in validation data is 89.455\n",
      "The epoch is 95, the loss is 90.032, the loss in validation data is 89.438\n",
      "The epoch is 96, the loss is 90.156, the loss in validation data is 89.610\n",
      "The epoch is 97, the loss is 89.974, the loss in validation data is 90.048\n",
      "The epoch is 98, the loss is 90.133, the loss in validation data is 89.709\n",
      "The epoch is 99, the loss is 89.993, the loss in validation data is 89.443\n",
      "The epoch is 100, the loss is 90.063, the loss in validation data is 89.452\n",
      "The epoch is 101, the loss is 90.038, the loss in validation data is 89.730\n",
      "The epoch is 102, the loss is 89.999, the loss in validation data is 89.899\n",
      "The epoch is 103, the loss is 90.062, the loss in validation data is 89.570\n",
      "The epoch is 104, the loss is 89.973, the loss in validation data is 89.448\n",
      "The epoch is 105, the loss is 90.049, the loss in validation data is 89.513\n",
      "The epoch is 106, the loss is 89.984, the loss in validation data is 89.779\n",
      "The epoch is 107, the loss is 90.014, the loss in validation data is 89.753\n",
      "The epoch is 108, the loss is 90.006, the loss in validation data is 89.513\n",
      "The epoch is 109, the loss is 89.984, the loss in validation data is 89.467\n",
      "The epoch is 110, the loss is 90.016, the loss in validation data is 89.586\n",
      "The epoch is 111, the loss is 89.973, the loss in validation data is 89.763\n",
      "The epoch is 112, the loss is 90.009, the loss in validation data is 89.647\n",
      "The epoch is 113, the loss is 89.979, the loss in validation data is 89.496\n",
      "The epoch is 114, the loss is 89.992, the loss in validation data is 89.501\n",
      "The epoch is 115, the loss is 89.989, the loss in validation data is 89.639\n",
      "The epoch is 116, the loss is 89.978, the loss in validation data is 89.714\n",
      "The epoch is 117, the loss is 89.994, the loss in validation data is 89.583\n",
      "The epoch is 118, the loss is 89.973, the loss in validation data is 89.500\n",
      "The epoch is 119, the loss is 89.990, the loss in validation data is 89.542\n",
      "The epoch is 120, the loss is 89.976, the loss in validation data is 89.662\n",
      "The epoch is 121, the loss is 89.982, the loss in validation data is 89.660\n",
      "The epoch is 122, the loss is 89.981, the loss in validation data is 89.550\n",
      "The epoch is 123, the loss is 89.975, the loss in validation data is 89.515\n",
      "The epoch is 124, the loss is 89.983, the loss in validation data is 89.580\n",
      "The epoch is 125, the loss is 89.973, the loss in validation data is 89.658\n",
      "The epoch is 126, the loss is 89.981, the loss in validation data is 89.616\n",
      "The epoch is 127, the loss is 89.975, the loss in validation data is 89.538\n",
      "The epoch is 128, the loss is 89.977, the loss in validation data is 89.537\n",
      "The epoch is 129, the loss is 89.977, the loss in validation data is 89.605\n",
      "The epoch is 130, the loss is 89.974, the loss in validation data is 89.641\n",
      "The epoch is 131, the loss is 89.978, the loss in validation data is 89.586\n",
      "The epoch is 132, the loss is 89.973, the loss in validation data is 89.539\n",
      "The epoch is 133, the loss is 89.977, the loss in validation data is 89.560\n",
      "The epoch is 134, the loss is 89.974, the loss in validation data is 89.616\n",
      "The epoch is 135, the loss is 89.975, the loss in validation data is 89.619\n",
      "The epoch is 136, the loss is 89.975, the loss in validation data is 89.568\n",
      "The epoch is 137, the loss is 89.973, the loss in validation data is 89.547\n",
      "The epoch is 138, the loss is 89.975, the loss in validation data is 89.579\n",
      "The epoch is 139, the loss is 89.973, the loss in validation data is 89.616\n",
      "The epoch is 140, the loss is 89.975, the loss in validation data is 89.599\n",
      "The epoch is 141, the loss is 89.973, the loss in validation data is 89.561\n",
      "The epoch is 142, the loss is 89.974, the loss in validation data is 89.559\n",
      "The epoch is 143, the loss is 89.974, the loss in validation data is 89.591\n",
      "The epoch is 144, the loss is 89.973, the loss in validation data is 89.609\n",
      "The epoch is 145, the loss is 89.974, the loss in validation data is 89.585\n",
      "The epoch is 146, the loss is 89.973, the loss in validation data is 89.561\n",
      "The epoch is 147, the loss is 89.974, the loss in validation data is 89.570\n",
      "The epoch is 148, the loss is 89.973, the loss in validation data is 89.597\n",
      "The epoch is 149, the loss is 89.973, the loss in validation data is 89.600\n",
      "The epoch is 0, the loss is 5072.812, the loss in validation data is 1897.360\n",
      "The epoch is 1, the loss is 1849.425, the loss in validation data is 3926.098\n",
      "The epoch is 2, the loss is 3990.039, the loss in validation data is 1260.537\n",
      "The epoch is 3, the loss is 1295.230, the loss in validation data is 777.513\n",
      "The epoch is 4, the loss is 747.412, the loss in validation data is 2210.007\n",
      "The epoch is 5, the loss is 2158.660, the loss in validation data is 120.196\n",
      "The epoch is 6, the loss is 112.481, the loss in validation data is 1495.867\n",
      "The epoch is 7, the loss is 1534.068, the loss in validation data is 819.265\n",
      "The epoch is 8, the loss is 846.206, the loss in validation data is 414.331\n",
      "The epoch is 9, the loss is 393.080, the loss in validation data is 1382.328\n",
      "The epoch is 10, the loss is 1341.813, the loss in validation data is 133.135\n",
      "The epoch is 11, the loss is 124.241, the loss in validation data is 859.686\n",
      "The epoch is 12, the loss is 887.420, the loss in validation data is 576.067\n",
      "The epoch is 13, the loss is 597.684, the loss in validation data is 240.699\n",
      "The epoch is 14, the loss is 225.620, the loss in validation data is 872.692\n",
      "The epoch is 15, the loss is 840.734, the loss in validation data is 137.254\n",
      "The epoch is 16, the loss is 128.026, the loss in validation data is 505.448\n",
      "The epoch is 17, the loss is 525.276, the loss in validation data is 408.275\n",
      "The epoch is 18, the loss is 425.371, the loss in validation data is 158.007\n",
      "The epoch is 19, the loss is 147.284, the loss in validation data is 561.448\n",
      "The epoch is 20, the loss is 536.216, the loss in validation data is 134.993\n",
      "The epoch is 21, the loss is 125.947, the loss in validation data is 310.702\n",
      "The epoch is 22, the loss is 324.587, the loss in validation data is 295.027\n",
      "The epoch is 23, the loss is 308.333, the loss in validation data is 119.889\n",
      "The epoch is 24, the loss is 112.204, the loss in validation data is 372.796\n",
      "The epoch is 25, the loss is 352.827, the loss in validation data is 129.340\n",
      "The epoch is 26, the loss is 120.770, the loss in validation data is 205.177\n",
      "The epoch is 27, the loss is 214.617, the loss in validation data is 220.071\n",
      "The epoch is 28, the loss is 230.237, the loss in validation data is 103.008\n",
      "The epoch is 29, the loss is 97.409, the loss in validation data is 259.234\n",
      "The epoch is 30, the loss is 243.364, the loss in validation data is 122.540\n",
      "The epoch is 31, the loss is 114.594, the loss in validation data is 148.955\n",
      "The epoch is 32, the loss is 155.085, the loss in validation data is 171.345\n",
      "The epoch is 33, the loss is 178.931, the loss in validation data is 95.902\n",
      "The epoch is 34, the loss is 91.707, the loss in validation data is 191.292\n",
      "The epoch is 35, the loss is 178.600, the loss in validation data is 115.943\n",
      "The epoch is 36, the loss is 108.672, the loss in validation data is 119.603\n",
      "The epoch is 37, the loss is 123.284, the loss in validation data is 140.207\n",
      "The epoch is 38, the loss is 145.692, the loss in validation data is 93.101\n",
      "The epoch is 39, the loss is 89.828, the loss in validation data is 150.855\n",
      "The epoch is 40, the loss is 140.617, the loss in validation data is 110.204\n",
      "The epoch is 41, the loss is 103.599, the loss in validation data is 104.666\n",
      "The epoch is 42, the loss is 106.546, the loss in validation data is 120.642\n",
      "The epoch is 43, the loss is 124.428, the loss in validation data is 92.090\n",
      "The epoch is 44, the loss is 89.402, the loss in validation data is 126.889\n",
      "The epoch is 45, the loss is 118.537, the loss in validation data is 105.532\n",
      "The epoch is 46, the loss is 99.551, the loss in validation data is 97.319\n",
      "The epoch is 47, the loss is 97.882, the loss in validation data is 108.561\n",
      "The epoch is 48, the loss is 110.982, the loss in validation data is 91.769\n",
      "The epoch is 49, the loss is 89.433, the loss in validation data is 112.725\n",
      "The epoch is 50, the loss is 105.816, the loss in validation data is 101.897\n",
      "The epoch is 51, the loss is 96.480, the loss in validation data is 93.875\n",
      "The epoch is 52, the loss is 93.483, the loss in validation data is 101.240\n",
      "The epoch is 53, the loss is 102.572, the loss in validation data is 91.684\n",
      "The epoch is 54, the loss is 89.544, the loss in validation data is 104.364\n",
      "The epoch is 55, the loss is 98.555, the loss in validation data is 99.157\n",
      "The epoch is 56, the loss is 94.234, the loss in validation data is 92.379\n",
      "The epoch is 57, the loss is 91.299, the loss in validation data is 96.898\n",
      "The epoch is 58, the loss is 97.365, the loss in validation data is 91.667\n",
      "The epoch is 59, the loss is 89.618, the loss in validation data is 99.424\n",
      "The epoch is 60, the loss is 94.450, the loss in validation data is 97.136\n",
      "The epoch is 61, the loss is 92.640, the loss in validation data is 91.814\n",
      "The epoch is 62, the loss is 90.244, the loss in validation data is 94.388\n",
      "The epoch is 63, the loss is 94.172, the loss in validation data is 91.664\n",
      "The epoch is 64, the loss is 89.640, the loss in validation data is 96.496\n",
      "The epoch is 65, the loss is 92.151, the loss in validation data is 95.671\n",
      "The epoch is 66, the loss is 91.537, the loss in validation data is 91.668\n",
      "The epoch is 67, the loss is 89.751, the loss in validation data is 92.986\n",
      "The epoch is 68, the loss is 92.232, the loss in validation data is 91.666\n",
      "The epoch is 69, the loss is 89.626, the loss in validation data is 94.750\n",
      "The epoch is 70, the loss is 90.879, the loss in validation data is 94.618\n",
      "The epoch is 71, the loss is 90.787, the loss in validation data is 91.689\n",
      "The epoch is 72, the loss is 89.531, the loss in validation data is 92.238\n",
      "The epoch is 73, the loss is 91.064, the loss in validation data is 91.671\n",
      "The epoch is 74, the loss is 89.591, the loss in validation data is 93.698\n",
      "The epoch is 75, the loss is 90.181, the loss in validation data is 93.867\n",
      "The epoch is 76, the loss is 90.288, the loss in validation data is 91.761\n",
      "The epoch is 77, the loss is 89.438, the loss in validation data is 91.869\n",
      "The epoch is 78, the loss is 90.368, the loss in validation data is 91.681\n",
      "The epoch is 79, the loss is 89.551, the loss in validation data is 93.058\n",
      "The epoch is 80, the loss is 89.804, the loss in validation data is 93.333\n",
      "The epoch is 81, the loss is 89.960, the loss in validation data is 91.837\n",
      "The epoch is 82, the loss is 89.403, the loss in validation data is 91.710\n",
      "The epoch is 83, the loss is 89.956, the loss in validation data is 91.697\n",
      "The epoch is 84, the loss is 89.513, the loss in validation data is 92.661\n",
      "The epoch is 85, the loss is 89.603, the loss in validation data is 92.953\n",
      "The epoch is 86, the loss is 89.748, the loss in validation data is 91.899\n",
      "The epoch is 87, the loss is 89.391, the loss in validation data is 91.664\n",
      "The epoch is 88, the loss is 89.714, the loss in validation data is 91.718\n",
      "The epoch is 89, the loss is 89.480, the loss in validation data is 92.412\n",
      "The epoch is 90, the loss is 89.497, the loss in validation data is 92.681\n",
      "The epoch is 91, the loss is 89.612, the loss in validation data is 91.942\n",
      "The epoch is 92, the loss is 89.389, the loss in validation data is 91.674\n",
      "The epoch is 93, the loss is 89.574, the loss in validation data is 91.742\n",
      "The epoch is 94, the loss is 89.454, the loss in validation data is 92.253\n",
      "The epoch is 95, the loss is 89.442, the loss in validation data is 92.486\n",
      "The epoch is 96, the loss is 89.526, the loss in validation data is 91.970\n",
      "The epoch is 97, the loss is 89.389, the loss in validation data is 91.709\n",
      "The epoch is 98, the loss is 89.493, the loss in validation data is 91.768\n",
      "The epoch is 99, the loss is 89.434, the loss in validation data is 92.149\n",
      "The epoch is 100, the loss is 89.414, the loss in validation data is 92.346\n",
      "The epoch is 101, the loss is 89.473, the loss in validation data is 91.986\n",
      "The epoch is 102, the loss is 89.390, the loss in validation data is 91.750\n",
      "The epoch is 103, the loss is 89.447, the loss in validation data is 91.793\n",
      "The epoch is 104, the loss is 89.420, the loss in validation data is 92.080\n",
      "The epoch is 105, the loss is 89.401, the loss in validation data is 92.243\n",
      "The epoch is 106, the loss is 89.439, the loss in validation data is 91.994\n",
      "The epoch is 107, the loss is 89.390, the loss in validation data is 91.791\n",
      "The epoch is 108, the loss is 89.421, the loss in validation data is 91.817\n",
      "The epoch is 109, the loss is 89.409, the loss in validation data is 92.035\n",
      "The epoch is 110, the loss is 89.394, the loss in validation data is 92.168\n",
      "The epoch is 111, the loss is 89.419, the loss in validation data is 91.996\n",
      "The epoch is 112, the loss is 89.390, the loss in validation data is 91.826\n",
      "The epoch is 113, the loss is 89.406, the loss in validation data is 91.839\n",
      "The epoch is 114, the loss is 89.402, the loss in validation data is 92.004\n",
      "The epoch is 115, the loss is 89.391, the loss in validation data is 92.113\n",
      "The epoch is 116, the loss is 89.407, the loss in validation data is 91.994\n",
      "The epoch is 117, the loss is 89.390, the loss in validation data is 91.856\n",
      "The epoch is 118, the loss is 89.398, the loss in validation data is 91.858\n",
      "The epoch is 119, the loss is 89.398, the loss in validation data is 91.984\n",
      "The epoch is 120, the loss is 89.389, the loss in validation data is 92.072\n",
      "The epoch is 121, the loss is 89.399, the loss in validation data is 91.991\n",
      "The epoch is 122, the loss is 89.390, the loss in validation data is 91.880\n",
      "The epoch is 123, the loss is 89.394, the loss in validation data is 91.875\n",
      "The epoch is 124, the loss is 89.394, the loss in validation data is 91.970\n",
      "The epoch is 125, the loss is 89.389, the loss in validation data is 92.042\n",
      "The epoch is 126, the loss is 89.395, the loss in validation data is 91.987\n",
      "The epoch is 127, the loss is 89.390, the loss in validation data is 91.898\n",
      "The epoch is 128, the loss is 89.391, the loss in validation data is 91.890\n",
      "The epoch is 129, the loss is 89.392, the loss in validation data is 91.961\n",
      "The epoch is 130, the loss is 89.389, the loss in validation data is 92.019\n",
      "The epoch is 131, the loss is 89.392, the loss in validation data is 91.982\n",
      "The epoch is 132, the loss is 89.389, the loss in validation data is 91.913\n",
      "The epoch is 133, the loss is 89.390, the loss in validation data is 91.902\n",
      "The epoch is 134, the loss is 89.391, the loss in validation data is 91.955\n",
      "The epoch is 135, the loss is 89.389, the loss in validation data is 92.002\n",
      "The epoch is 136, the loss is 89.391, the loss in validation data is 91.977\n",
      "The epoch is 137, the loss is 89.389, the loss in validation data is 91.923\n",
      "The epoch is 138, the loss is 89.389, the loss in validation data is 91.912\n",
      "The epoch is 139, the loss is 89.390, the loss in validation data is 91.951\n",
      "The epoch is 140, the loss is 89.389, the loss in validation data is 91.989\n",
      "The epoch is 141, the loss is 89.390, the loss in validation data is 91.973\n",
      "The epoch is 142, the loss is 89.389, the loss in validation data is 91.931\n",
      "The epoch is 143, the loss is 89.389, the loss in validation data is 91.920\n",
      "The epoch is 144, the loss is 89.389, the loss in validation data is 91.949\n",
      "The epoch is 145, the loss is 89.389, the loss in validation data is 91.979\n",
      "The epoch is 146, the loss is 89.389, the loss in validation data is 91.969\n",
      "The epoch is 147, the loss is 89.389, the loss in validation data is 91.937\n",
      "The epoch is 148, the loss is 89.389, the loss in validation data is 91.926\n",
      "The epoch is 149, the loss is 89.389, the loss in validation data is 91.948\n",
      "The epoch is 0, the loss is 5026.981, the loss in validation data is 1052.360\n",
      "The epoch is 1, the loss is 1106.396, the loss in validation data is 5805.224\n",
      "The epoch is 2, the loss is 5679.296, the loss in validation data is 941.775\n",
      "The epoch is 3, the loss is 893.726, the loss in validation data is 2957.543\n",
      "The epoch is 4, the loss is 3049.385, the loss in validation data is 1920.414\n",
      "The epoch is 5, the loss is 1994.049, the loss in validation data is 1312.248\n",
      "The epoch is 6, the loss is 1254.365, the loss in validation data is 2764.484\n",
      "The epoch is 7, the loss is 2678.272, the loss in validation data is 247.297\n",
      "The epoch is 8, the loss is 269.815, the loss in validation data is 2539.958\n",
      "The epoch is 9, the loss is 2624.944, the loss in validation data is 106.984\n",
      "The epoch is 10, the loss is 115.350, the loss in validation data is 2064.634\n",
      "The epoch is 11, the loss is 1990.729, the loss in validation data is 497.822\n",
      "The epoch is 12, the loss is 464.902, the loss in validation data is 1101.146\n",
      "The epoch is 13, the loss is 1156.205, the loss in validation data is 855.839\n",
      "The epoch is 14, the loss is 903.925, the loss in validation data is 510.985\n",
      "The epoch is 15, the loss is 477.518, the loss in validation data is 1192.770\n",
      "The epoch is 16, the loss is 1137.852, the loss in validation data is 123.763\n",
      "The epoch is 17, the loss is 134.948, the loss in validation data is 1023.977\n",
      "The epoch is 18, the loss is 1076.944, the loss in validation data is 103.736\n",
      "The epoch is 19, the loss is 111.416, the loss in validation data is 847.993\n",
      "The epoch is 20, the loss is 802.671, the loss in validation data is 288.125\n",
      "The epoch is 21, the loss is 265.542, the loss in validation data is 438.146\n",
      "The epoch is 22, the loss is 470.995, the loss in validation data is 403.339\n",
      "The epoch is 23, the loss is 434.571, the loss in validation data is 235.823\n",
      "The epoch is 24, the loss is 216.615, the loss in validation data is 546.542\n",
      "The epoch is 25, the loss is 511.641, the loss in validation data is 94.644\n",
      "The epoch is 26, the loss is 99.802, the loss in validation data is 439.333\n",
      "The epoch is 27, the loss is 472.235, the loss in validation data is 98.148\n",
      "The epoch is 28, the loss is 104.430, the loss in validation data is 383.367\n",
      "The epoch is 29, the loss is 355.629, the loss in validation data is 185.785\n",
      "The epoch is 30, the loss is 170.437, the loss in validation data is 205.423\n",
      "The epoch is 31, the loss is 224.907, the loss in validation data is 214.392\n",
      "The epoch is 32, the loss is 234.567, the loss in validation data is 141.378\n",
      "The epoch is 33, the loss is 130.439, the loss in validation data is 280.784\n",
      "The epoch is 34, the loss is 258.645, the loss in validation data is 89.557\n",
      "The epoch is 35, the loss is 91.612, the loss in validation data is 216.870\n",
      "The epoch is 36, the loss is 237.231, the loss in validation data is 93.740\n",
      "The epoch is 37, the loss is 98.551, the loss in validation data is 205.318\n",
      "The epoch is 38, the loss is 188.367, the loss in validation data is 136.525\n",
      "The epoch is 39, the loss is 126.169, the loss in validation data is 125.792\n",
      "The epoch is 40, the loss is 137.265, the loss in validation data is 137.169\n",
      "The epoch is 41, the loss is 150.128, the loss in validation data is 108.712\n",
      "The epoch is 42, the loss is 102.530, the loss in validation data is 171.063\n",
      "The epoch is 43, the loss is 157.035, the loss in validation data is 89.523\n",
      "The epoch is 44, the loss is 90.056, the loss in validation data is 133.831\n",
      "The epoch is 45, the loss is 146.374, the loss in validation data is 91.124\n",
      "The epoch is 46, the loss is 94.648, the loss in validation data is 136.506\n",
      "The epoch is 47, the loss is 126.153, the loss in validation data is 112.933\n",
      "The epoch is 48, the loss is 105.979, the loss in validation data is 99.644\n",
      "The epoch is 49, the loss is 106.336, the loss in validation data is 106.511\n",
      "The epoch is 50, the loss is 114.782, the loss in validation data is 97.175\n",
      "The epoch is 51, the loss is 93.702, the loss in validation data is 125.346\n",
      "The epoch is 52, the loss is 116.459, the loss in validation data is 90.042\n",
      "The epoch is 53, the loss is 89.884, the loss in validation data is 103.746\n",
      "The epoch is 54, the loss is 111.428, the loss in validation data is 89.866\n",
      "The epoch is 55, the loss is 92.358, the loss in validation data is 109.482\n",
      "The epoch is 56, the loss is 103.153, the loss in validation data is 101.586\n",
      "The epoch is 57, the loss is 96.928, the loss in validation data is 91.679\n",
      "The epoch is 58, the loss is 95.529, the loss in validation data is 94.864\n",
      "The epoch is 59, the loss is 100.102, the loss in validation data is 92.936\n",
      "The epoch is 60, the loss is 90.990, the loss in validation data is 105.984\n",
      "The epoch is 61, the loss is 100.346, the loss in validation data is 90.335\n",
      "The epoch is 62, the loss is 89.908, the loss in validation data is 93.390\n",
      "The epoch is 63, the loss is 98.057, the loss in validation data is 89.407\n",
      "The epoch is 64, the loss is 91.116, the loss in validation data is 98.586\n",
      "The epoch is 65, the loss is 94.705, the loss in validation data is 96.051\n",
      "The epoch is 66, the loss is 92.931, the loss in validation data is 89.625\n",
      "The epoch is 67, the loss is 91.795, the loss in validation data is 90.766\n",
      "The epoch is 68, the loss is 94.050, the loss in validation data is 91.286\n",
      "The epoch is 69, the loss is 90.187, the loss in validation data is 97.572\n",
      "The epoch is 70, the loss is 93.981, the loss in validation data is 90.416\n",
      "The epoch is 71, the loss is 89.921, the loss in validation data is 90.166\n",
      "The epoch is 72, the loss is 92.968, the loss in validation data is 89.343\n",
      "The epoch is 73, the loss is 90.478, the loss in validation data is 94.020\n",
      "The epoch is 74, the loss is 91.622, the loss in validation data is 93.287\n",
      "The epoch is 75, the loss is 91.188, the loss in validation data is 89.339\n",
      "The epoch is 76, the loss is 90.521, the loss in validation data is 89.543\n",
      "The epoch is 77, the loss is 91.572, the loss in validation data is 90.597\n",
      "The epoch is 78, the loss is 89.961, the loss in validation data is 93.785\n",
      "The epoch is 79, the loss is 91.480, the loss in validation data is 90.390\n",
      "The epoch is 80, the loss is 89.917, the loss in validation data is 89.390\n",
      "The epoch is 81, the loss is 91.041, the loss in validation data is 89.438\n",
      "The epoch is 82, the loss is 90.163, the loss in validation data is 92.008\n",
      "The epoch is 83, the loss is 90.506, the loss in validation data is 91.862\n",
      "The epoch is 84, the loss is 90.437, the loss in validation data is 89.488\n",
      "The epoch is 85, the loss is 90.093, the loss in validation data is 89.338\n",
      "The epoch is 86, the loss is 90.564, the loss in validation data is 90.291\n",
      "The epoch is 87, the loss is 89.901, the loss in validation data is 92.001\n",
      "The epoch is 88, the loss is 90.503, the loss in validation data is 90.327\n",
      "The epoch is 89, the loss is 89.906, the loss in validation data is 89.373\n",
      "The epoch is 90, the loss is 90.316, the loss in validation data is 89.575\n",
      "The epoch is 91, the loss is 90.012, the loss in validation data is 91.067\n",
      "The epoch is 92, the loss is 90.105, the loss in validation data is 91.099\n",
      "The epoch is 93, the loss is 90.116, the loss in validation data is 89.681\n",
      "The epoch is 94, the loss is 89.951, the loss in validation data is 89.442\n",
      "The epoch is 95, the loss is 90.156, the loss in validation data is 90.149\n",
      "The epoch is 96, the loss is 89.887, the loss in validation data is 91.117\n",
      "The epoch is 97, the loss is 90.122, the loss in validation data is 90.262\n",
      "The epoch is 98, the loss is 89.897, the loss in validation data is 89.536\n",
      "The epoch is 99, the loss is 90.044, the loss in validation data is 89.703\n",
      "The epoch is 100, the loss is 89.942, the loss in validation data is 90.600\n",
      "The epoch is 101, the loss is 89.961, the loss in validation data is 90.675\n",
      "The epoch is 102, the loss is 89.981, the loss in validation data is 89.828\n",
      "The epoch is 103, the loss is 89.905, the loss in validation data is 89.604\n",
      "The epoch is 104, the loss is 89.992, the loss in validation data is 90.084\n",
      "The epoch is 105, the loss is 89.884, the loss in validation data is 90.655\n",
      "The epoch is 106, the loss is 89.976, the loss in validation data is 90.206\n",
      "The epoch is 107, the loss is 89.891, the loss in validation data is 89.700\n",
      "The epoch is 108, the loss is 89.943, the loss in validation data is 89.807\n",
      "The epoch is 109, the loss is 89.910, the loss in validation data is 90.357\n",
      "The epoch is 110, the loss is 89.911, the loss in validation data is 90.430\n",
      "The epoch is 111, the loss is 89.924, the loss in validation data is 89.924\n",
      "The epoch is 112, the loss is 89.890, the loss in validation data is 89.745\n",
      "The epoch is 113, the loss is 89.927, the loss in validation data is 90.054\n",
      "The epoch is 114, the loss is 89.884, the loss in validation data is 90.403\n",
      "The epoch is 115, the loss is 89.919, the loss in validation data is 90.162\n",
      "The epoch is 116, the loss is 89.888, the loss in validation data is 89.825\n",
      "The epoch is 117, the loss is 89.906, the loss in validation data is 89.884\n",
      "The epoch is 118, the loss is 89.895, the loss in validation data is 90.224\n",
      "The epoch is 119, the loss is 89.893, the loss in validation data is 90.285\n",
      "The epoch is 120, the loss is 89.900, the loss in validation data is 89.981\n",
      "The epoch is 121, the loss is 89.886, the loss in validation data is 89.849\n",
      "The epoch is 122, the loss is 89.901, the loss in validation data is 90.043\n",
      "The epoch is 123, the loss is 89.884, the loss in validation data is 90.260\n",
      "The epoch is 124, the loss is 89.897, the loss in validation data is 90.129\n",
      "The epoch is 125, the loss is 89.886, the loss in validation data is 89.910\n",
      "The epoch is 126, the loss is 89.892, the loss in validation data is 89.939\n",
      "The epoch is 127, the loss is 89.889, the loss in validation data is 90.150\n",
      "The epoch is 128, the loss is 89.887, the loss in validation data is 90.197\n",
      "The epoch is 129, the loss is 89.891, the loss in validation data is 90.014\n",
      "The epoch is 130, the loss is 89.884, the loss in validation data is 89.921\n",
      "The epoch is 131, the loss is 89.891, the loss in validation data is 90.040\n",
      "The epoch is 132, the loss is 89.884, the loss in validation data is 90.177\n",
      "The epoch is 133, the loss is 89.889, the loss in validation data is 90.105\n",
      "The epoch is 134, the loss is 89.885, the loss in validation data is 89.965\n",
      "The epoch is 135, the loss is 89.887, the loss in validation data is 89.977\n",
      "The epoch is 136, the loss is 89.886, the loss in validation data is 90.108\n",
      "The epoch is 137, the loss is 89.885, the loss in validation data is 90.143\n",
      "The epoch is 138, the loss is 89.887, the loss in validation data is 90.033\n",
      "The epoch is 139, the loss is 89.884, the loss in validation data is 89.969\n",
      "The epoch is 140, the loss is 89.887, the loss in validation data is 90.040\n",
      "The epoch is 141, the loss is 89.884, the loss in validation data is 90.127\n",
      "The epoch is 142, the loss is 89.886, the loss in validation data is 90.088\n",
      "The epoch is 143, the loss is 89.884, the loss in validation data is 89.999\n",
      "The epoch is 144, the loss is 89.885, the loss in validation data is 90.003\n",
      "The epoch is 145, the loss is 89.885, the loss in validation data is 90.084\n",
      "The epoch is 146, the loss is 89.884, the loss in validation data is 90.109\n",
      "The epoch is 147, the loss is 89.885, the loss in validation data is 90.043\n",
      "The epoch is 148, the loss is 89.884, the loss in validation data is 90.000\n",
      "The epoch is 149, the loss is 89.885, the loss in validation data is 90.042\n",
      "-0.002962670345329821\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = torch.from_numpy(X_train[train_ids]).float()\n",
    "    fold_y_train = torch.from_numpy(y_train[train_ids]).float()\n",
    "    fold_X_valid = torch.from_numpy(X_train[valid_ids]).float()\n",
    "    fold_y_valid = torch.from_numpy(y_train[valid_ids]).float()\n",
    "\n",
    "    # train model\n",
    "    model = NNModel()\n",
    "    optimizer = SGD(model.parameters(), lr=0.015, momentum=0.9)\n",
    "    epoch_num = 150\n",
    "    for epoch in range(epoch_num):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(fold_X_train)\n",
    "        loss = mse_loss(output, fold_y_train)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        valid_loss = mse_loss(model(fold_X_valid), fold_y_valid)\n",
    "        print(\"The epoch is {}, the loss is {:.03f}, the loss in validation data is {:.03f}\".format(epoch, loss, valid_loss))\n",
    "\n",
    "    fold_y_pred = model(fold_X_valid).detach().numpy()\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.00000</td>\n",
       "      <td>77.0000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>52.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>86.00000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>52.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.98037</td>\n",
       "      <td>70.7006</td>\n",
       "      <td>74.506813</td>\n",
       "      <td>73.756241</td>\n",
       "      <td>68.706367</td>\n",
       "      <td>72.723038</td>\n",
       "      <td>75.560249</td>\n",
       "      <td>68.03923</td>\n",
       "      <td>71.611771</td>\n",
       "      <td>74.690208</td>\n",
       "      <td>...</td>\n",
       "      <td>76.683571</td>\n",
       "      <td>76.612625</td>\n",
       "      <td>72.068871</td>\n",
       "      <td>70.635918</td>\n",
       "      <td>65.719597</td>\n",
       "      <td>69.181099</td>\n",
       "      <td>69.32547</td>\n",
       "      <td>69.093559</td>\n",
       "      <td>72.001694</td>\n",
       "      <td>75.453476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1          2          3          4          5          6    \\\n",
       "0  88.00000  77.0000  66.000000  63.000000  70.000000  49.000000  77.000000   \n",
       "1  70.98037  70.7006  74.506813  73.756241  68.706367  72.723038  75.560249   \n",
       "\n",
       "        7          8          9    ...        217        218        219  \\\n",
       "0  85.00000  63.000000  52.999996  ...  77.000000  76.000000  80.000000   \n",
       "1  68.03923  71.611771  74.690208  ...  76.683571  76.612625  72.068871   \n",
       "\n",
       "         220        221        222       223        224        225        226  \n",
       "0  56.000000  69.000000  75.000000  86.00000  68.000000  71.000000  52.999996  \n",
       "1  70.635918  65.719597  69.181099  69.32547  69.093559  72.001694  75.453476  \n",
       "\n",
       "[2 rows x 227 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(fold_y_valid.detach().numpy() * 100).ravel(), (fold_y_pred * 100).ravel()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>771</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>773</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>774</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>775</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     y\n",
       "0      0  61.0\n",
       "1      1  76.0\n",
       "2      2  70.0\n",
       "3      3  70.0\n",
       "4      4  72.0\n",
       "..   ...   ...\n",
       "771  771  66.0\n",
       "772  772  76.0\n",
       "773  773  75.0\n",
       "774  774  71.0\n",
       "775  775  60.0\n",
       "\n",
       "[776 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(n_estimators=200, max_depth=7, learning_rate=0.1, n_jobs=20)\n",
    "model.fit(X_train, y_train.ravel())\n",
    "y_pred = np.round(model.predict(X_test))\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=[\"y\"], index=data_X_test.index).reset_index()\n",
    "y_pred_df[\"id\"] = y_pred_df[\"id\"].astype(int)\n",
    "y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df.to_csv(\"result_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
