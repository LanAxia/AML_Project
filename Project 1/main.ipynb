{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, r_regression\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, Linear, Dropout\n",
    "from torch.nn.functional import tanh, softmax, mse_loss, relu\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# load and split data\n",
    "data_X_train = pd.read_csv('Data/X_train.csv', header=0, index_col=0)\n",
    "data_y_train = pd.read_csv('Data/y_train.csv', header=0, index_col=0)\n",
    "data_X_test = pd.read_csv('Data/X_test.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData Shape: 1212 x 832\\nData Lost: a lot\\ndata scale: large\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data info\n",
    "data_X_train.describe()\n",
    "\"\"\"\n",
    "Data Shape: 1212 x 832\n",
    "Data Lost: a lot\n",
    "data scale: large\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# transfer data to numpy\n",
    "X_train = data_X_train.to_numpy()\n",
    "y_train = data_y_train.to_numpy()\n",
    "X_test = data_X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理缺省值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_train = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 删除变化过小的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 in X_train.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 皮尔森系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lanhongyi/opt/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(832,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = r_regression(X_train, y_train.ravel())\n",
    "cc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 删减特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV\n",
    "estimator = LinearRegression()\n",
    "selector = RFECV(estimator, step=1, cv=5, scoring='r2')\n",
    "selector.fit(X_train, y_train)\n",
    "feature_ranks = selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# store the feature ranking\n",
    "# pd.DataFrame(selector.ranking_).to_csv(\"Temp/feature_ranking.csv\", header=False, index=False)\n",
    "feature_ranks = pd.read_csv(\"Temp/feature_ranking.csv\", header=None, index_col=None).to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# choose features (top 95%)\n",
    "def select_features(x, rank, threshold=0.8):\n",
    "    drop_feature_ids = np.where(rank > int(threshold * max(rank)))\n",
    "    selected_x = np.delete(x, drop_feature_ids, axis=1)\n",
    "    return selected_x\n",
    "\n",
    "X_train = select_features(X_train, feature_ranks, 0.95)\n",
    "X_test = select_features(X_test, feature_ranks, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保留特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 噪声探测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5, 3.5, 4.5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "！！！该方法具有较高的不确定性，不能保证有效\n",
    "思路：\n",
    "    1. 以每5年为一个period，计算数据到中心点的距离\n",
    "    2. 剔除距离最大的5%的数据\n",
    "\"\"\"\n",
    "deleted_sample_ids = []\n",
    "for start_year in np.arange(y_train.min(), y_train.max() + 1, 5):\n",
    "    cluster_x_train = X_train[y_train >= start_year and y_train < start_year + 5] \n",
    "    center_point = np.mean(cluster_x_train, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.890191269931073\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_score = 0\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_score += r2_score(fold_y_valid, fold_y_pred)\n",
    "fold_score /= fold_num\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019787009919412422\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_score = 0\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = KernelRidge(kernel=\"rbf\")\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_score += r2_score(fold_y_valid, fold_y_pred)\n",
    "fold_score /= fold_num\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749308857165471\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process Regressor (Matern)\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GaussianProcessRegressor(kernel=Matern(nu=0.5, length_scale=1), random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01484695627455086\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process Regressor (RBF)\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GaussianProcessRegressor(kernel=RBF(length_scale=10), random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27278034373557075\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = SVR(kernel=\"rbf\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45761414755344837\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=0, criterion=\"squared_error\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.88352200279015\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = IsolationForest(n_estimators=100, max_features=0.6, random_state=0)\n",
    "    model.fit(fold_X_train, fold_y_train)\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4756961780493696\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4110280800135076\n"
     ]
    }
   ],
   "source": [
    "# Adaboost Regressor\n",
    "fold_num = 5\n",
    "\n",
    "kf = KFold(n_splits=fold_num)\n",
    "fold_scores = []\n",
    "for i, (train_ids, valid_ids) in enumerate(kf.split(X_train)):\n",
    "    # split validation data\n",
    "    fold_X_train = X_train[train_ids]\n",
    "    fold_y_train = y_train[train_ids]\n",
    "    fold_X_valid = X_train[valid_ids]\n",
    "    fold_y_valid = y_train[valid_ids]\n",
    "\n",
    "    # train model\n",
    "    model = AdaBoostRegressor(n_estimators=100, learning_rate=0.1, loss=\"square\")\n",
    "    model.fit(fold_X_train, fold_y_train.ravel())\n",
    "    fold_y_pred = model.predict(fold_X_valid)\n",
    "\n",
    "    # calculate score\n",
    "    fold_scores.append(r2_score(fold_y_valid, fold_y_pred))\n",
    "fold_score = np.average(fold_scores)\n",
    "print(fold_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
