{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# import custom functions\n",
    "from utils import load_zipped_pickle, save_zipped_pickle\n",
    "\n",
    "DATA_DIR = \"Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "train_data = load_zipped_pickle(os.path.join(DATA_DIR, \"train.pkl\"))\n",
    "test_data = load_zipped_pickle(os.path.join(DATA_DIR, \"test.pkl\"))\n",
    "samples = load_zipped_pickle(os.path.join(DATA_DIR, \"sample.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112, 334)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][\"video\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'video', 'box', 'label', 'frames', 'dataset']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 低分辨率的数据不需要进一步处理，直接提取有标签的数据。\n",
    "# 高分辨率的数据需要进行切分，切分为一个个112*112的子图形和标签\n",
    "def tailor_img(img: np.array, target_size: tuple = (112, 112), stripe: int = 2) -> [np.array]:\n",
    "    tailored_imgs = []\n",
    "    for i in range(0, img.shape[0] - target_size[0] + 1, stripe):\n",
    "        for j in range(0, img.shape[1] - target_size[1] + 1, stripe):\n",
    "            sub_img = img[i:i + target_size[0], j:j + target_size[1]]\n",
    "            tailored_imgs.append(sub_img)\n",
    "    return tailored_imgs\n",
    "\n",
    "low_resolution_data = [x for x in train_data if x[\"video\"].shape[0] == 112 and x[\"video\"].shape[1] == 112]\n",
    "high_resolution_data = [x for x in train_data if x[\"video\"].shape[0] != 112 or x[\"video\"].shape[1] != 112]\n",
    "\n",
    "# 将低分辨率数据转换为训练所用的(帧数，高，宽)数据\n",
    "low_resolution_x = np.concatenate([x[\"video\"][:, :, x[\"frames\"]].transpose((2, 0, 1)) for x in low_resolution_data], axis=0) # 将shape转换为 (帧数，高，宽)\n",
    "low_resolution_y = np.concatenate([y[\"label\"][:, :, y[\"frames\"]].transpose((2, 0, 1)) for y in low_resolution_data], axis=0)\n",
    "\n",
    "# 对高分辨数据进行裁切，并转为训练所用的(帧数，高，宽)数据\n",
    "high_resolution_x = []\n",
    "high_resolution_y = []\n",
    "for video in high_resolution_data:\n",
    "    images_x, images_y = video[\"video\"][:, :, video[\"frames\"]], video[\"label\"][:, :, video[\"frames\"]]\n",
    "    images_x = images_x.transpose((2, 0, 1)) # 将shape转换为 (帧数，高，宽)\n",
    "    images_y = images_y.transpose((2, 0, 1))\n",
    "    for image_x, image_y in zip(images_x, images_y):\n",
    "        tailored_imgs_x = tailor_img(image_x, target_size=(112, 112), stripe=3)\n",
    "        tailored_imgs_y = tailor_img(image_y, target_size=(112, 112), stripe=3)\n",
    "\n",
    "        high_resolution_x += tailored_imgs_x\n",
    "        high_resolution_y += tailored_imgs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将低维数据输出位png图片\n",
    "# image_array是归一化的二维浮点数矩阵\n",
    "img_x = low_resolution_x[1]\n",
    "img_y = low_resolution_y[1]\n",
    "img_x = Image.fromarray(img_x)\n",
    "img_y = Image.fromarray(img_y)\n",
    "img_x = img_x.convert('L')  # 这样才能转为灰度图，如果是彩色图则改L为‘RGB’\n",
    "img_y = img_y.convert('L')  # 这样才能转为灰度图，如果是彩色图则改L为‘RGB’\n",
    "img_x.save('./pictures/low_resolution_x.png')\n",
    "img_y.save('./pictures/low_resolution_y.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将高维数据输出为png图片\n",
    "# image_array是归一化的二维浮点数矩阵\n",
    "img_x = high_resolution_x[0]\n",
    "img_y = high_resolution_x[0]\n",
    "img_x = Image.fromarray(img_x)\n",
    "img_y = Image.fromarray(img_y)\n",
    "img_x = img_x.convert('L')  # 这样才能转为灰度图，如果是彩色图则改L为‘RGB’\n",
    "img_y = img_y.convert('L')  # 这样才能转为灰度图，如果是彩色图则改L为‘RGB’\n",
    "img_x.save('./pictures/high_resolution_x.png')\n",
    "img_y.save('./pictures/high_resolution_y.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 筛选高分辨数据中有效的数据\n",
    "valid_ids = []\n",
    "high_resolution_x_new = []\n",
    "high_resolution_y_new = []\n",
    "for i, (x, y) in enumerate(zip(high_resolution_x, high_resolution_y)):\n",
    "    if y.sum() > 20:\n",
    "        valid_ids.append(i)\n",
    "        high_resolution_x_new.append(x)\n",
    "        high_resolution_y_new.append(y)\n",
    "high_resolution_x = np.array(high_resolution_x_new)\n",
    "high_resolution_y = np.array(high_resolution_y_new)\n",
    "# 保存训练数据\n",
    "np.save(\"./Data/high_resolution_x.npy\", high_resolution_x)\n",
    "np.save(\"./Data/high_resolution_y.npy\", high_resolution_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
