{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "\n",
    "# import custom modules\n",
    "from UNet import UNet, Nested_UNet\n",
    "from utils import load_zipped_pickle, save_zipped_pickle\n",
    "\n",
    "# config device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "DATA_DIR = \"Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "test_data = load_zipped_pickle(os.path.join(DATA_DIR, \"test.pkl\"))\n",
    "processed_test_data = load_zipped_pickle(os.path.join(DATA_DIR, \"test_crop.pkl\"))\n",
    "\n",
    "# 加载目标框数据\n",
    "with open(os.path.join(\"./Data/\", \"box.yaml\"), 'r') as f:\n",
    "    box = yaml.load(f, yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 定义预测模型所用的采样和复原函数\n",
    "def pad(img: np.ndarray, pad_size: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    将图片基于指定的pad__size进行padding\n",
    "    pad_size: (pad_top, pad_bottom, pad_left, pad_right)\n",
    "    \"\"\"\n",
    "    pad_img = np.zeros((img.shape[0] + pad_size[0] + pad_size[1], img.shape[1] + pad_size[2] + pad_size[3]), dtype=img.dtype)\n",
    "    pad_img[pad_size[0]:img.shape[0] + pad_size[0], pad_size[2]:img.shape[1] + pad_size[2]] = img\n",
    "    return pad_img\n",
    "\n",
    "\n",
    "def pad_to_window_size(img: np.ndarray, window_size: tuple = (112, 112)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    将图片基于指定的window_size进行padding\n",
    "    \"\"\"\n",
    "    pad_height = (img.shape[0] // window_size[0] + 1) * window_size[0] - img.shape[0]\n",
    "    pad_width = (img.shape[1] // window_size[1] + 1) * window_size[1] - img.shape[1]\n",
    "    pad_size = (pad_height // 2, pad_height - (pad_height // 2), pad_width // 2, pad_width - (pad_width // 2))\n",
    "    return pad(img, pad_size), pad_size\n",
    "\n",
    "\n",
    "def sample_by_tailor(img: np.ndarray, window_size: tuple = (112, 112)) -> ([np.ndarray], tuple):\n",
    "    \"\"\"\n",
    "    将图片基于指定的window_size进行裁剪\n",
    "    \"\"\"\n",
    "    pad_img, pad_size = pad_to_window_size(img, window_size)\n",
    "    samples = []\n",
    "    for i in range(pad_img.shape[0] // window_size[0]):\n",
    "        for j in range(pad_img.shape[1] // window_size[1]):\n",
    "            samples.append(pad_img[i * window_size[0]:(i + 1) * window_size[0], j * window_size[1]:(j + 1) * window_size[1]])\n",
    "    return samples, pad_size, (pad_img.shape[0] // window_size[0], pad_img.shape[1] // window_size[1])\n",
    "\n",
    "\n",
    "def traverse_by_tailor(imgs: [np.ndarray], pad_size: tuple, original_shape: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    将裁切完的图片基于裁切方式还原为原始图片\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i in range(original_shape[0]):\n",
    "        i_row = np.concatenate(imgs[i * original_shape[1]:(i + 1) * original_shape[1]], axis=1)\n",
    "        rows.append(i_row)\n",
    "    pad_img = np.concatenate(rows, axis=0)\n",
    "    img = pad_img[pad_size[0]:pad_img.shape[0] - pad_size[1], pad_size[2]:pad_img.shape[1] - pad_size[3]]\n",
    "    return img\n",
    "\n",
    "\n",
    "def sample_by_window(img: np.ndarray, window_size: tuple = (112, 112), stride=16) -> ([np.ndarray], tuple):\n",
    "    \"\"\"\n",
    "    将图片基于指定的window_size进行裁剪\n",
    "    \"\"\"\n",
    "    pad_img, pad_size = pad_to_window_size(img, window_size)\n",
    "    samples = []\n",
    "    for i in range(0, pad_img.shape[0] - window_size[0] + 1, stride):\n",
    "        for j in range(0, pad_img.shape[1] - window_size[1] + 1, stride):\n",
    "            samples.append(pad_img[i:i + window_size[0], j:j + window_size[1]])\n",
    "    return samples, pad_size, ((pad_img.shape[0] - window_size[0]) // stride + 1, (pad_img.shape[1] - window_size[1]) // stride + 1)\n",
    "\n",
    "\n",
    "def traverse_by_window(imgs: [np.ndarray], pad_size: tuple, original_shape: tuple, stride=16) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    将按照窗口采样的数据还原为原始图片\n",
    "    \"\"\"\n",
    "    pad_height = imgs[0].shape[0] + stride * (original_shape[0] - 1)\n",
    "    pad_width = imgs[0].shape[1] + stride * (original_shape[1] - 1)\n",
    "    pad_img = np.zeros((pad_height, pad_width))\n",
    "\n",
    "    # 复原padding过后的图片，此时某些像素可能因为多次叠加而有过高的值\n",
    "    for i in range(original_shape[0]):\n",
    "        for j in range(original_shape[1]):\n",
    "            pad_img[stride * i:stride * i + imgs[0].shape[0], stride * j:stride * j + imgs[0].shape[1]] += imgs[i * original_shape[1] + j]\n",
    "    \n",
    "    # 复原权重矩阵，用全为1的img子图模拟叠加过程，获得每个像素点的叠加次数\n",
    "    weight_matrix = np.zeros_like(pad_img)\n",
    "    weight_imgs = np.ones_like(imgs[0])\n",
    "    for i in range(original_shape[0]):\n",
    "        for j in range(original_shape[1]):\n",
    "            weight_matrix[stride * i:stride * i + imgs[0].shape[0], stride * j:stride * j + imgs[0].shape[1]] += weight_imgs\n",
    "    \n",
    "    # 复原padding后的图像并去除多余的padding\n",
    "    pad_img /= weight_matrix\n",
    "    img = pad_img[pad_size[0]:pad_img.shape[0] - pad_size[1], pad_size[2]:pad_img.shape[1] - pad_size[3]]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def predict_by_torch(x: torch.Tensor, model: nn.Module) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    使用torch模型进行预测\n",
    "    \"\"\"\n",
    "    # 生成预测数据集和数据加载\n",
    "    dataset = TensorDataset(x)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    model.eval()  # 将模型的状态设置为eval\n",
    "    pred = []\n",
    "\n",
    "    # 批量进行预测\n",
    "    with torch.no_grad():\n",
    "        for (x_batch,) in dataloader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = F.sigmoid(model(x_batch)) # 预测完的结果需要计算sigmoid\n",
    "            pred.append(y_batch)\n",
    "    pred = torch.cat(pred, dim=0)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def predict(x: np.ndarray, model: nn.Module):\n",
    "    x = torch.from_numpy(x).float().unsqueeze(1)  # 原始数据：(sample_num, height, width)，转化后：(sample_num, 1, height, width) 增加channel的维度\n",
    "    pred = predict_by_torch(x, model).squeeze(1)  # 去除channel的维度，恢复为原始的维度\n",
    "    pred = pred.to(cpu_device).detach().numpy()  # 转化为np.ndarray\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [32:58<00:00, 98.94s/it, img_i=61]  \n"
     ]
    }
   ],
   "source": [
    "# 通过windows进行采样并预测(bilinear unet)\n",
    "\n",
    "# 加载模型\n",
    "model = UNet(1, 1, bilinear=True).to(device)\n",
    "model.load_state_dict(torch.load(\"./Model/UNet_4_4_bilinear.pt\"))\n",
    "\n",
    "pred_data = []\n",
    "with trange(len(test_data), desc=\"Predicting: \") as t:\n",
    "    postfix = dict()\n",
    "    for video_i in t:\n",
    "        video = test_data[video_i]\n",
    "        video_name = video[\"name\"]\n",
    "        video_imgs = video[\"video\"].transpose(2, 0, 1)  # 调整为(Frames, height, width)\n",
    "        video_pred = []\n",
    "        for img_i, img in enumerate(video_imgs):\n",
    "            img_samples, pad_size, sample_shape = sample_by_window(img, window_size=(112, 112), stride=16)\n",
    "            img_samples = np.array(img_samples)\n",
    "            img_samples_pred = predict(img_samples, model)\n",
    "            img_pred = traverse_by_window(img_samples_pred, pad_size, sample_shape, stride=16)\n",
    "            video_pred.append(img_pred)\n",
    "            postfix[\"img_i\"] = img_i\n",
    "            t.set_postfix(postfix)\n",
    "        video_pred = np.array(video_pred).transpose(1, 2, 0)\n",
    "        pred_data.append({\"name\": video_name, \"prediction\": video_pred})\n",
    "save_zipped_pickle(pred_data, os.path.join(\"Prediction\", \"UNet_4_4_bilinear.pkl\"))  # 此数据仍需后处理，预测结果是浮点数，需要转化为0和1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [26:46<00:00, 80.33s/it, img_i=61] \n"
     ]
    }
   ],
   "source": [
    "# 通过windows进行采样并预测(convtranspose unet)\n",
    "\n",
    "# 加载模型\n",
    "model = UNet(1, 1, bilinear=False).to(device)\n",
    "model.load_state_dict(torch.load(\"./Model/UNet_4_4_transpose_conv.pt\"))\n",
    "\n",
    "pred_data = []\n",
    "with trange(len(test_data), desc=\"Predicting: \") as t:\n",
    "    postfix = dict()\n",
    "    for video_i in t:\n",
    "        video = test_data[video_i]\n",
    "        video_name = video[\"name\"]\n",
    "        video_imgs = video[\"video\"].transpose(2, 0, 1)  # 调整为(Frames, height, width)\n",
    "        video_pred = []\n",
    "        for img_i, img in enumerate(video_imgs):\n",
    "            img_samples, pad_size, sample_shape = sample_by_window(img, window_size=(112, 112), stride=16)\n",
    "            img_samples = np.array(img_samples)\n",
    "            img_samples_pred = predict(img_samples, model)\n",
    "            img_pred = traverse_by_window(img_samples_pred, pad_size, sample_shape, stride=16)\n",
    "            video_pred.append(img_pred)\n",
    "            postfix[\"img_i\"] = img_i\n",
    "            t.set_postfix(postfix)\n",
    "        video_pred = np.array(video_pred).transpose(1, 2, 0)\n",
    "        pred_data.append({\"name\": video_name, \"prediction\": video_pred})\n",
    "save_zipped_pickle(pred_data, os.path.join(\"Prediction\", \"UNet_4_4_transpose_conv.pkl\"))  # 此数据仍需后处理，预测结果是浮点数，需要转化为0和1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [1:40:39<00:00, 301.97s/it, img_i=61]  \n"
     ]
    }
   ],
   "source": [
    "# 通过windows进行采样并预测(unet++)\n",
    "\n",
    "# 加载模型\n",
    "model = Nested_UNet(1, 1).to(device)\n",
    "model.load_state_dict(torch.load(\"./Model/NestedUNet_4_4.pt\"))\n",
    "\n",
    "pred_data = []\n",
    "with trange(len(test_data), desc=\"Predicting: \") as t:\n",
    "    postfix = dict()\n",
    "    for video_i in t:\n",
    "        video = test_data[video_i]\n",
    "        video_name = video[\"name\"]\n",
    "        video_imgs = video[\"video\"].transpose(2, 0, 1)  # 调整为(Frames, height, width)\n",
    "        video_pred = []\n",
    "        for img_i, img in enumerate(video_imgs):\n",
    "            img_samples, pad_size, sample_shape = sample_by_window(img, window_size=(112, 112), stride=16)\n",
    "            img_samples = np.array(img_samples)\n",
    "            img_samples_pred = predict(img_samples, model)\n",
    "            img_pred = traverse_by_window(img_samples_pred, pad_size, sample_shape, stride=16)\n",
    "            video_pred.append(img_pred)\n",
    "            postfix[\"img_i\"] = img_i\n",
    "            t.set_postfix(postfix)\n",
    "        video_pred = np.array(video_pred).transpose(1, 2, 0)\n",
    "        pred_data.append({\"name\": video_name, \"prediction\": video_pred})\n",
    "save_zipped_pickle(pred_data, os.path.join(\"Prediction\", \"Nested_UNet_4_4.pkl\"))  # 此数据仍需后处理，预测结果是浮点数，需要转化为0和1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [19:34<00:00, 58.70s/it, img_i=61] \n"
     ]
    }
   ],
   "source": [
    "# 通过windows进行采样并预测(unet processed data)\n",
    "\n",
    "# 加载模型\n",
    "model = UNet(1, 1, bilinear=True).to(device)\n",
    "model.load_state_dict(torch.load(\"./Model/UNet_4_4_bilinear_processed.pt\"))\n",
    "\n",
    "pred_data = []\n",
    "with trange(len(test_data), desc=\"Predicting: \") as t:\n",
    "    postfix = dict()\n",
    "    for video_i in t:\n",
    "        original_video = test_data[video_i]\n",
    "        video_name = original_video[\"name\"]\n",
    "        original_video_imgs = original_video[\"video\"].transpose(2, 0, 1)  # 调整为(Frames, height, width)\n",
    "        tailored_video = processed_test_data[video_i]\n",
    "        tailored_video_imgs = tailored_video[\"images\"].transpose(2, 0, 1)\n",
    "        tailored_video_shapes = tailored_video[\"shapes\"]\n",
    "        video_pred = []\n",
    "        for img_i, (original_img, tailored_img) in enumerate(zip(original_video_imgs, tailored_video_imgs)):\n",
    "            img_samples, pad_size, sample_shape = sample_by_window(tailored_img, window_size=(256, 256), stride=32)\n",
    "            img_samples = np.array(img_samples)\n",
    "            img_samples_pred = predict(img_samples, model)\n",
    "            img_pred = traverse_by_window(img_samples_pred, pad_size, sample_shape, stride=32)\n",
    "            img_pred_new = np.ones_like(original_img)\n",
    "            img_pred_new[tailored_video_shapes[2]:tailored_video_shapes[3], tailored_video_shapes[0]:tailored_video_shapes[1]] = img_pred  # 将裁切的结果进行还原（待预测数据是512*512的，需要填充回一个全0的矩阵中）\n",
    "            img_pred = img_pred_new\n",
    "            video_pred.append(img_pred)\n",
    "            postfix[\"img_i\"] = img_i\n",
    "            t.set_postfix(postfix)\n",
    "        video_pred = np.array(video_pred).transpose(1, 2, 0)\n",
    "        pred_data.append({\"name\": video_name, \"prediction\": video_pred})\n",
    "save_zipped_pickle(pred_data, os.path.join(\"Prediction\", \"UNet_Processed_Data.pkl\"))  # 此数据仍需后处理，预测结果是浮点数，需要转化为0和1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [26:04<00:00, 78.25s/it, img_i=61]  \n"
     ]
    }
   ],
   "source": [
    "# 通过windows进行采样并预测(unet high resolution)\n",
    "\n",
    "# 加载模型\n",
    "model = UNet(1, 1, bilinear=True).to(device)\n",
    "model.load_state_dict(torch.load(\"./Model/UNet_4_4_bilinear_high_resolution.pt\"))\n",
    "\n",
    "pred_data = []\n",
    "with trange(len(test_data), desc=\"Predicting: \") as t:\n",
    "    postfix = dict()\n",
    "    for video_i in t:\n",
    "        video = test_data[video_i]\n",
    "        video_name = video[\"name\"]\n",
    "        video_imgs = video[\"video\"].transpose(2, 0, 1)  # 调整为(Frames, height, width)\n",
    "        video_pred = []\n",
    "        for img_i, img in enumerate(video_imgs):\n",
    "            img_samples, pad_size, sample_shape = sample_by_window(img, window_size=(256, 256), stride=32)\n",
    "            img_samples = np.array(img_samples)\n",
    "            img_samples_pred = predict(img_samples, model)\n",
    "            img_pred = traverse_by_window(img_samples_pred, pad_size, sample_shape, stride=32)\n",
    "            video_pred.append(img_pred)\n",
    "            postfix[\"img_i\"] = img_i\n",
    "            t.set_postfix(postfix)\n",
    "        video_pred = np.array(video_pred).transpose(1, 2, 0)\n",
    "        pred_data.append({\"name\": video_name, \"prediction\": video_pred})\n",
    "save_zipped_pickle(pred_data, os.path.join(\"Prediction\", \"UNet_High_Resolution.pkl\"))  # 此数据仍需后处理，预测结果是浮点数，需要转化为0和1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 从保存的数据中加载预测结果\n",
    "pred_data_unet_bilinear = load_zipped_pickle(os.path.join(\"Prediction\", \"UNet_4_4_bilinear.pkl\"))\n",
    "pred_data_unet_conv = load_zipped_pickle(os.path.join(\"Prediction\", \"UNet_4_4_transpose_conv.pkl\"))\n",
    "pred_data_unet_nested = load_zipped_pickle(os.path.join(\"Prediction\", \"Nested_UNet_4_4.pkl\"))\n",
    "pred_data_unet_processed = load_zipped_pickle(os.path.join(\"Prediction\", \"UNet_Processed_Data.pkl\"))\n",
    "pred_data_unet_high_resolution = load_zipped_pickle(os.path.join(\"Prediction\", \"UNet_High_Resolution.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# 对预测结果进行处理\n",
    "prob_threshold = 0.5\n",
    "\n",
    "transformed_pred = []\n",
    "for video_bilinear, video_conv, video_nested, video_box_arg in zip(pred_data_unet_bilinear, pred_data_unet_conv, pred_data_unet_nested, box):\n",
    "    video_transformed = {\"name\": video_bilinear[\"name\"]}\n",
    "    video_bilinear = video_bilinear[\"prediction\"]\n",
    "    video_conv = video_conv[\"prediction\"]\n",
    "    video_nested = video_nested[\"prediction\"]\n",
    "    video_pred = (video_bilinear + video_conv + video_nested + video_high_resolution) / 4  # 对三个模型的预测结果进行平均\n",
    "\n",
    "    # 在这里开始处理\n",
    "    video_box = np.zeros_like(video_pred)\n",
    "    video_box[video_box_arg[0]:video_box_arg[1], video_box_arg[2]:video_box_arg[3], :] = 1\n",
    "    video_pred = (video_pred > prob_threshold) * video_box # 将预测结果按照阈值进行处理，并转换数据类型\n",
    "    video_pred = (video_pred == 1) # 转换数组的数据类型为bool值\n",
    "\n",
    "    video_transformed[\"prediction\"] = video_pred\n",
    "    transformed_pred.append(video_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对预测结果进行处理\n",
    "prob_threshold = 0.5\n",
    "\n",
    "transformed_pred = []\n",
    "for video, video_box_arg in zip(pred_data_unet_processed, box):\n",
    "    video_transformed = {\"name\": video[\"name\"]}\n",
    "    video_pred = video[\"prediction\"]\n",
    "\n",
    "    # 在这里开始处理\n",
    "    video_box = np.zeros_like(video_pred)\n",
    "    video_box[video_box_arg[0]:video_box_arg[1], video_box_arg[2]:video_box_arg[3], :] = 1\n",
    "    video_pred = (video_pred > prob_threshold) * video_box # 将预测结果按照阈值进行处理，并转换数据类型\n",
    "    video_pred = (video_pred == 1) # 转换数组的数据类型为bool值\n",
    "\n",
    "    video_transformed[\"prediction\"] = video_pred\n",
    "    transformed_pred.append(video_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存转化完的预测结果\n",
    "save_zipped_pickle(transformed_pred, \"./Prediction/result.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
